{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp zero_shot_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from operator import itemgetter\n",
    "\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import bs4\n",
    "import feedparser\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from ktrain import text \n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kuba/Projects/pytorch_hackathon\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "medium_publications = [\n",
    "    'the-artificial-impostor',\n",
    "    'pytorch',\n",
    "    'dair.ai',\n",
    "    'towards-artificial-intelligence',\n",
    "    'swlh',\n",
    "    '@ODSC',\n",
    "    'doctrine',\n",
    "    'paperswithcode'\n",
    "]\n",
    "\n",
    "\n",
    "medium_url_template = 'https://medium.com/feed/{}'\n",
    "medium_url = medium_url_template.format(medium_publications[0])\n",
    "medium_urls = [medium_url_template.format(publication) for publication in medium_publications]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "subreddits = [\n",
    "    'MachineLearning',\n",
    "    'deeplearning',\n",
    "    'datascience',\n",
    "    'cognitivelinguistics',\n",
    "    'TopOfArxivSanity',\n",
    "    'kaggle'\n",
    "]\n",
    "\n",
    "reddit_url_template = 'https://www.reddit.com/r/{}/.rss'\n",
    "reddit_url = reddit_url_template.format(subreddits[0])\n",
    "reddit_urls = [reddit_url_template.format(subreddit) for subreddit in subreddits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def get_article_text(article):\n",
    "    article_html_content = article['content'][0]['value']\n",
    "    article_text = bs4.BeautifulSoup(article_html_content).text\n",
    "    return article_text\n",
    "\n",
    "\n",
    "def get_feed_article_texts(feed):\n",
    "    return [get_article_text(article) for article in feed['entries'] if 'content' in article.keys()]\n",
    "\n",
    "\n",
    "def get_feed_article_df(feed):\n",
    "    feed_df = pd.DataFrame.from_records(feed['entries'])\n",
    "    feed_df['text'] = feed_df['summary'].apply(lambda s: bs4.BeautifulSoup(s).text)\n",
    "    return feed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "paperswithcode_url = 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest' \n",
    "hackernews_url = 'https://news.ycombinator.com/rss' \n",
    "rss_feed_urls = [paperswithcode_url, hackernews_url] + medium_urls + reddit_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_feed_df(feed_urls):\n",
    "    feeds = [\n",
    "        feedparser.parse(feed_url)\n",
    "        for feed_url in tqdm.tqdm(feed_urls)\n",
    "    ]\n",
    "    return pd.concat(\n",
    "        [\n",
    "            get_feed_article_df(feed)\n",
    "            for feed in feeds\n",
    "            if len(feed['entries']) > 0\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n"
     ]
    }
   ],
   "source": [
    "feed_df = get_feed_df(rss_feed_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title_detail</th>\n",
       "      <th>links</th>\n",
       "      <th>link</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_detail</th>\n",
       "      <th>id</th>\n",
       "      <th>guidislink</th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "      <th>...</th>\n",
       "      <th>published_parsed</th>\n",
       "      <th>comments</th>\n",
       "      <th>authors</th>\n",
       "      <th>author</th>\n",
       "      <th>author_detail</th>\n",
       "      <th>updated</th>\n",
       "      <th>updated_parsed</th>\n",
       "      <th>content</th>\n",
       "      <th>href</th>\n",
       "      <th>media_thumbnail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I2L-MeshNet: Image-to-Lixel Prediction Network for Accurate 3D Human Pose and Mesh Estimation from a Single RGB Image</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'I2L-MeshNet: Image-to-Lixel Prediction Network for Accurate 3D Human Pose and Mesh Estimation from a Single RGB Image'}</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/i2l-meshnet-image-to-lixel-prediction-network'}]</td>\n",
       "      <td>https://paperswithcode.com/paper/i2l-meshnet-image-to-lixel-prediction-network</td>\n",
       "      <td>Most of the previous image-based 3D human pose and mesh estimation methods estimate parameters of the human mesh model from an input image. &lt;p&gt;Code: &lt;a href=\"https://github.com/mks0601/I2L-MeshNet_RELEASE\"&gt;https://github.com/mks0601/I2L-MeshNet_R...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Most of the previous image-based 3D human pose and mesh estimation methods estimate parameters of the human mesh model from an in...</td>\n",
       "      <td>https://paperswithcode.com/paper/i2l-meshnet-image-to-lixel-prediction-network</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'term': '3d hand pose estimation', 'scheme': None, 'label': None}, {'term': '3d human pose estimation', 'scheme': None, 'label': None}]</td>\n",
       "      <td>Most of the previous image-based 3D human pose and mesh estimation methods estimate parameters of the human mesh model from an input image. Code: https://github.com/mks0601/I2L-MeshNet_RELEASE</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polysemy Deciphering Network for Robust Human-Object Interaction Detection</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Polysemy Deciphering Network for Robust Human-Object Interaction Detection'}</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/polysemy-deciphering-network-for-robust-human'}]</td>\n",
       "      <td>https://paperswithcode.com/paper/polysemy-deciphering-network-for-robust-human</td>\n",
       "      <td>To address this issue, in this paper, we propose a novel Polysemy Deciphering Network (PD-Net) that decodes the visual polysemy of verbs for HOI detection in three distinct ways. &lt;p&gt;Code: &lt;a href=\"https://github.com/MuchHair/PD-Net\"&gt;https://githu...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'To address this issue, in this paper, we propose a novel Polysemy Deciphering Network (PD-Net) that decodes the visual polysemy o...</td>\n",
       "      <td>https://paperswithcode.com/paper/polysemy-deciphering-network-for-robust-human</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'term': 'Human-object interaction detection', 'scheme': None, 'label': None}, {'term': 'Scene understanding', 'scheme': None, 'label': None}]</td>\n",
       "      <td>To address this issue, in this paper, we propose a novel Polysemy Deciphering Network (PD-Net) that decodes the visual polysemy of verbs for HOI detection in three distinct ways. Code: https://github.com/MuchHair/PD-Net</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cascade Graph Neural Networks for RGB-D Salient Object Detection</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Cascade Graph Neural Networks for RGB-D Salient Object Detection'}</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/cascade-graph-neural-networks-for-rgb-d'}]</td>\n",
       "      <td>https://paperswithcode.com/paper/cascade-graph-neural-networks-for-rgb-d</td>\n",
       "      <td>Current works either simply distill prior knowledge from the corresponding depth map for handling the RGB-image or blindly fuse color and geometric information to generate the coarse depth-aware representations, hindering the performance of RGB-D...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Current works either simply distill prior knowledge from the corresponding depth map for handling the RGB-image or blindly fuse c...</td>\n",
       "      <td>https://paperswithcode.com/paper/cascade-graph-neural-networks-for-rgb-d</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'term': 'Salient object detection', 'scheme': None, 'label': None}]</td>\n",
       "      <td>Current works either simply distill prior knowledge from the corresponding depth map for handling the RGB-image or blindly fuse color and geometric information to generate the coarse depth-aware representations, hindering the performance of RGB-D...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Convolutional Complex Knowledge Graph Embeddings</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Convolutional Complex Knowledge Graph Embeddings'}</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/convolutional-complex-knowledge-graph'}]</td>\n",
       "      <td>https://paperswithcode.com/paper/convolutional-complex-knowledge-graph</td>\n",
       "      <td>In this paper, we study the problem of learning continuous vector representations of knowledge graphs for predicting missing links. &lt;p&gt;Code: &lt;a href=\"https://github.com/conex-kge/ConEx\"&gt;https://github.com/conex-kge/ConEx&lt;/a&gt;&lt;/p&gt;</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'In this paper, we study the problem of learning continuous vector representations of knowledge graphs for predicting missing link...</td>\n",
       "      <td>https://paperswithcode.com/paper/convolutional-complex-knowledge-graph</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'term': 'Knowledge graph embeddings', 'scheme': None, 'label': None}, {'term': 'Knowledge graphs', 'scheme': None, 'label': None}, {'term': 'Link prediction', 'scheme': None, 'label': None}]</td>\n",
       "      <td>In this paper, we study the problem of learning continuous vector representations of knowledge graphs for predicting missing links. Code: https://github.com/conex-kge/ConEx</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quantum State Tomography with Conditional Generative Adversarial Networks</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Quantum State Tomography with Conditional Generative Adversarial Networks'}</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/quantum-state-tomography-with-conditional'}]</td>\n",
       "      <td>https://paperswithcode.com/paper/quantum-state-tomography-with-conditional</td>\n",
       "      <td>We augment a CGAN with custom neural-network layers that enable conversion of output from any standard neural network into a physical density matrix. &lt;p&gt;Code: &lt;a href=\"https://github.com/quantshah/qst-cgan\"&gt;https://github.com/quantshah/qst-cgan&lt;/...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'We augment a CGAN with custom neural-network layers that enable conversion of output from any standard neural network into a phys...</td>\n",
       "      <td>https://paperswithcode.com/paper/quantum-state-tomography-with-conditional</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'term': 'Quantum state tomography', 'scheme': None, 'label': None}]</td>\n",
       "      <td>We augment a CGAN with custom neural-network layers that enable conversion of output from any standard neural network into a physical density matrix. Code: https://github.com/quantshah/qst-cgan</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                   title  \\\n",
       "0  I2L-MeshNet: Image-to-Lixel Prediction Network for Accurate 3D Human Pose and Mesh Estimation from a Single RGB Image   \n",
       "1                                             Polysemy Deciphering Network for Robust Human-Object Interaction Detection   \n",
       "2                                                       Cascade Graph Neural Networks for RGB-D Salient Object Detection   \n",
       "3                                                                       Convolutional Complex Knowledge Graph Embeddings   \n",
       "4                                              Quantum State Tomography with Conditional Generative Adversarial Networks   \n",
       "\n",
       "                                                                                                                                                                                                                                    title_detail  \\\n",
       "0  {'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'I2L-MeshNet: Image-to-Lixel Prediction Network for Accurate 3D Human Pose and Mesh Estimation from a Single RGB Image'}   \n",
       "1                                             {'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Polysemy Deciphering Network for Robust Human-Object Interaction Detection'}   \n",
       "2                                                       {'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Cascade Graph Neural Networks for RGB-D Salient Object Detection'}   \n",
       "3                                                                       {'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Convolutional Complex Knowledge Graph Embeddings'}   \n",
       "4                                              {'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Quantum State Tomography with Conditional Generative Adversarial Networks'}   \n",
       "\n",
       "                                                                                                                                   links  \\\n",
       "0  [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/i2l-meshnet-image-to-lixel-prediction-network'}]   \n",
       "1  [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/polysemy-deciphering-network-for-robust-human'}]   \n",
       "2        [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/cascade-graph-neural-networks-for-rgb-d'}]   \n",
       "3          [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/convolutional-complex-knowledge-graph'}]   \n",
       "4      [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/quantum-state-tomography-with-conditional'}]   \n",
       "\n",
       "                                                                             link  \\\n",
       "0  https://paperswithcode.com/paper/i2l-meshnet-image-to-lixel-prediction-network   \n",
       "1  https://paperswithcode.com/paper/polysemy-deciphering-network-for-robust-human   \n",
       "2        https://paperswithcode.com/paper/cascade-graph-neural-networks-for-rgb-d   \n",
       "3          https://paperswithcode.com/paper/convolutional-complex-knowledge-graph   \n",
       "4      https://paperswithcode.com/paper/quantum-state-tomography-with-conditional   \n",
       "\n",
       "                                                                                                                                                                                                                                                     summary  \\\n",
       "0  Most of the previous image-based 3D human pose and mesh estimation methods estimate parameters of the human mesh model from an input image. <p>Code: <a href=\"https://github.com/mks0601/I2L-MeshNet_RELEASE\">https://github.com/mks0601/I2L-MeshNet_R...   \n",
       "1  To address this issue, in this paper, we propose a novel Polysemy Deciphering Network (PD-Net) that decodes the visual polysemy of verbs for HOI detection in three distinct ways. <p>Code: <a href=\"https://github.com/MuchHair/PD-Net\">https://githu...   \n",
       "2  Current works either simply distill prior knowledge from the corresponding depth map for handling the RGB-image or blindly fuse color and geometric information to generate the coarse depth-aware representations, hindering the performance of RGB-D...   \n",
       "3                       In this paper, we study the problem of learning continuous vector representations of knowledge graphs for predicting missing links. <p>Code: <a href=\"https://github.com/conex-kge/ConEx\">https://github.com/conex-kge/ConEx</a></p>   \n",
       "4  We augment a CGAN with custom neural-network layers that enable conversion of output from any standard neural network into a physical density matrix. <p>Code: <a href=\"https://github.com/quantshah/qst-cgan\">https://github.com/quantshah/qst-cgan</...   \n",
       "\n",
       "                                                                                                                                                                                                                                              summary_detail  \\\n",
       "0  {'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Most of the previous image-based 3D human pose and mesh estimation methods estimate parameters of the human mesh model from an in...   \n",
       "1  {'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'To address this issue, in this paper, we propose a novel Polysemy Deciphering Network (PD-Net) that decodes the visual polysemy o...   \n",
       "2  {'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Current works either simply distill prior knowledge from the corresponding depth map for handling the RGB-image or blindly fuse c...   \n",
       "3  {'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'In this paper, we study the problem of learning continuous vector representations of knowledge graphs for predicting missing link...   \n",
       "4  {'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'We augment a CGAN with custom neural-network layers that enable conversion of output from any standard neural network into a phys...   \n",
       "\n",
       "                                                                               id  \\\n",
       "0  https://paperswithcode.com/paper/i2l-meshnet-image-to-lixel-prediction-network   \n",
       "1  https://paperswithcode.com/paper/polysemy-deciphering-network-for-robust-human   \n",
       "2        https://paperswithcode.com/paper/cascade-graph-neural-networks-for-rgb-d   \n",
       "3          https://paperswithcode.com/paper/convolutional-complex-knowledge-graph   \n",
       "4      https://paperswithcode.com/paper/quantum-state-tomography-with-conditional   \n",
       "\n",
       "  guidislink  \\\n",
       "0      False   \n",
       "1      False   \n",
       "2      False   \n",
       "3      False   \n",
       "4      False   \n",
       "\n",
       "                                                                                                                                                                                               tags  \\\n",
       "0                                                         [{'term': '3d hand pose estimation', 'scheme': None, 'label': None}, {'term': '3d human pose estimation', 'scheme': None, 'label': None}]   \n",
       "1                                                   [{'term': 'Human-object interaction detection', 'scheme': None, 'label': None}, {'term': 'Scene understanding', 'scheme': None, 'label': None}]   \n",
       "2                                                                                                                             [{'term': 'Salient object detection', 'scheme': None, 'label': None}]   \n",
       "3  [{'term': 'Knowledge graph embeddings', 'scheme': None, 'label': None}, {'term': 'Knowledge graphs', 'scheme': None, 'label': None}, {'term': 'Link prediction', 'scheme': None, 'label': None}]   \n",
       "4                                                                                                                             [{'term': 'Quantum state tomography', 'scheme': None, 'label': None}]   \n",
       "\n",
       "                                                                                                                                                                                                                                                        text  \\\n",
       "0                                                           Most of the previous image-based 3D human pose and mesh estimation methods estimate parameters of the human mesh model from an input image. Code: https://github.com/mks0601/I2L-MeshNet_RELEASE   \n",
       "1                                To address this issue, in this paper, we propose a novel Polysemy Deciphering Network (PD-Net) that decodes the visual polysemy of verbs for HOI detection in three distinct ways. Code: https://github.com/MuchHair/PD-Net   \n",
       "2  Current works either simply distill prior knowledge from the corresponding depth map for handling the RGB-image or blindly fuse color and geometric information to generate the coarse depth-aware representations, hindering the performance of RGB-D...   \n",
       "3                                                                               In this paper, we study the problem of learning continuous vector representations of knowledge graphs for predicting missing links. Code: https://github.com/conex-kge/ConEx   \n",
       "4                                                          We augment a CGAN with custom neural-network layers that enable conversion of output from any standard neural network into a physical density matrix. Code: https://github.com/quantshah/qst-cgan   \n",
       "\n",
       "   ... published_parsed comments authors author author_detail updated  \\\n",
       "0  ...              NaN      NaN     NaN    NaN           NaN     NaN   \n",
       "1  ...              NaN      NaN     NaN    NaN           NaN     NaN   \n",
       "2  ...              NaN      NaN     NaN    NaN           NaN     NaN   \n",
       "3  ...              NaN      NaN     NaN    NaN           NaN     NaN   \n",
       "4  ...              NaN      NaN     NaN    NaN           NaN     NaN   \n",
       "\n",
       "  updated_parsed content href media_thumbnail  \n",
       "0            NaN     NaN  NaN             NaN  \n",
       "1            NaN     NaN  NaN             NaN  \n",
       "2            NaN     NaN  NaN             NaN  \n",
       "3            NaN     NaN  NaN             NaN  \n",
       "4            NaN     NaN  NaN             NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kuba/Projects/pytorch_hackathon\r\n"
     ]
    }
   ],
   "source": [
    "!pwd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs\t\t Makefile~\t    pytorch_hackathon.egg-info\tsettings.ini~\r\n",
      "feed_topics.csv  models\t\t    README.md\t\t\tsetup.py\r\n",
      "github_search\t notebooks\t    requirements.txt\t\tstreamlit\r\n",
      "Makefile\t pytorch_hackathon  settings.ini\r\n"
     ]
    }
   ],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "zsl_clf = text.ZeroShotClassifier(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ktrain.text.zsl.core.ZeroShotClassifier at 0x7f43560b3950>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zsl_clf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_article = feed_df.iloc[0]\n",
    "example_article_text = example_article['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "topic_strings = [\n",
    "    'deep learning',\n",
    "    'natural language processing',\n",
    "    'computer vision',\n",
    "    'visualization',\n",
    "    'industry',\n",
    "    'implementation',\n",
    "    'computer programming',\n",
    "    'reddit question',\n",
    "    'research',\n",
    "    'startup'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForSequenceClassification(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(50265, 1024, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "      (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "      (layers): ModuleList(\n",
       "        (0): EncoderLayer(\n",
       "          (self_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): EncoderLayer(\n",
       "          (self_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): EncoderLayer(\n",
       "          (self_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): EncoderLayer(\n",
       "          (self_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): EncoderLayer(\n",
       "          (self_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): EncoderLayer(\n",
       "          (self_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): EncoderLayer(\n",
       "          (self_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): EncoderLayer(\n",
       "          (self_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): EncoderLayer(\n",
       "          (self_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): EncoderLayer(\n",
       "          (self_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): EncoderLayer(\n",
       "          (self_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): EncoderLayer(\n",
       "          (self_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "      (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "      (layers): ModuleList(\n",
       "        (0): DecoderLayer(\n",
       "          (self_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): DecoderLayer(\n",
       "          (self_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): DecoderLayer(\n",
       "          (self_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): DecoderLayer(\n",
       "          (self_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): DecoderLayer(\n",
       "          (self_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): DecoderLayer(\n",
       "          (self_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): DecoderLayer(\n",
       "          (self_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): DecoderLayer(\n",
       "          (self_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): DecoderLayer(\n",
       "          (self_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): DecoderLayer(\n",
       "          (self_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): DecoderLayer(\n",
       "          (self_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): DecoderLayer(\n",
       "          (self_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): SelfAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (classification_head): BartClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zsl_clf.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(295, 21)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def get_zero_shot_classification_results(zsl_clf, text, topic_strings, max_length=128, sort=True):\n",
    "    results = zsl_clf.predict(text, topic_strings=topic_strings, include_labels=True, batch_size=len(topic_strings), max_length=max_length)\n",
    "    if sort:\n",
    "        return sorted(results, key=itemgetter(1), reverse=True)\n",
    "    else:\n",
    "        return results\n",
    "\n",
    "\n",
    "def get_zero_shot_classification_results_df(zsl_clf, texts, topic_strings):\n",
    "    results_df = pd.DataFrame(np.zeros((len(texts), len(topic_strings))), columns=sorted(topic_strings))\n",
    "    for i, text in enumerate(tqdm.tqdm(texts)):\n",
    "        results = get_zero_shot_classification_results(zsl_clf, text, topic_strings)\n",
    "        results_df.iloc[i] = pd.Series(dict(sorted(results, key=itemgetter(0))))\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_zero_shot_classification_results(zsl_clf, example_article_text, topic_strings)\n",
    "results = sorted(results, key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "computer programming           0.724514\n",
       "research                       0.703937\n",
       "computer vision                0.663395\n",
       "visualization                  0.287664\n",
       "deep learning                  0.113755\n",
       "startup                        0.035245\n",
       "implementation                 0.019770\n",
       "industry                       0.016407\n",
       "reddit question                0.007256\n",
       "natural language processing    0.000321\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 295/295 [00:53<00:00,  5.48it/s]\n"
     ]
    }
   ],
   "source": [
    "results_df = get_zero_shot_classification_results_df(\n",
    "    zsl_clf,\n",
    "    feed_df['text'],\n",
    "    topic_strings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(295, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_df[['text']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title_detail</th>\n",
       "      <th>links</th>\n",
       "      <th>link</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_detail</th>\n",
       "      <th>id</th>\n",
       "      <th>guidislink</th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "      <th>...</th>\n",
       "      <th>published_parsed</th>\n",
       "      <th>comments</th>\n",
       "      <th>authors</th>\n",
       "      <th>author</th>\n",
       "      <th>author_detail</th>\n",
       "      <th>updated</th>\n",
       "      <th>updated_parsed</th>\n",
       "      <th>content</th>\n",
       "      <th>href</th>\n",
       "      <th>media_thumbnail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I2L-MeshNet: Image-to-Lixel Prediction Network for Accurate 3D Human Pose and Mesh Estimation from a Single RGB Image</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'I2L-MeshNet: Image-to-Lixel Prediction Network for Accurate 3D Human Pose and Mesh Estimation from a Single RGB Image'}</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/i2l-meshnet-image-to-lixel-prediction-network'}]</td>\n",
       "      <td>https://paperswithcode.com/paper/i2l-meshnet-image-to-lixel-prediction-network</td>\n",
       "      <td>Most of the previous image-based 3D human pose and mesh estimation methods estimate parameters of the human mesh model from an input image. &lt;p&gt;Code: &lt;a href=\"https://github.com/mks0601/I2L-MeshNet_RELEASE\"&gt;https://github.com/mks0601/I2L-MeshNet_R...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Most of the previous image-based 3D human pose and mesh estimation methods estimate parameters of the human mesh model from an in...</td>\n",
       "      <td>https://paperswithcode.com/paper/i2l-meshnet-image-to-lixel-prediction-network</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'term': '3d hand pose estimation', 'scheme': None, 'label': None}, {'term': '3d human pose estimation', 'scheme': None, 'label': None}]</td>\n",
       "      <td>Most of the previous image-based 3D human pose and mesh estimation methods estimate parameters of the human mesh model from an input image. Code: https://github.com/mks0601/I2L-MeshNet_RELEASE</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polysemy Deciphering Network for Robust Human-Object Interaction Detection</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Polysemy Deciphering Network for Robust Human-Object Interaction Detection'}</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/polysemy-deciphering-network-for-robust-human'}]</td>\n",
       "      <td>https://paperswithcode.com/paper/polysemy-deciphering-network-for-robust-human</td>\n",
       "      <td>To address this issue, in this paper, we propose a novel Polysemy Deciphering Network (PD-Net) that decodes the visual polysemy of verbs for HOI detection in three distinct ways. &lt;p&gt;Code: &lt;a href=\"https://github.com/MuchHair/PD-Net\"&gt;https://githu...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'To address this issue, in this paper, we propose a novel Polysemy Deciphering Network (PD-Net) that decodes the visual polysemy o...</td>\n",
       "      <td>https://paperswithcode.com/paper/polysemy-deciphering-network-for-robust-human</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'term': 'Human-object interaction detection', 'scheme': None, 'label': None}, {'term': 'Scene understanding', 'scheme': None, 'label': None}]</td>\n",
       "      <td>To address this issue, in this paper, we propose a novel Polysemy Deciphering Network (PD-Net) that decodes the visual polysemy of verbs for HOI detection in three distinct ways. Code: https://github.com/MuchHair/PD-Net</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cascade Graph Neural Networks for RGB-D Salient Object Detection</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Cascade Graph Neural Networks for RGB-D Salient Object Detection'}</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/cascade-graph-neural-networks-for-rgb-d'}]</td>\n",
       "      <td>https://paperswithcode.com/paper/cascade-graph-neural-networks-for-rgb-d</td>\n",
       "      <td>Current works either simply distill prior knowledge from the corresponding depth map for handling the RGB-image or blindly fuse color and geometric information to generate the coarse depth-aware representations, hindering the performance of RGB-D...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Current works either simply distill prior knowledge from the corresponding depth map for handling the RGB-image or blindly fuse c...</td>\n",
       "      <td>https://paperswithcode.com/paper/cascade-graph-neural-networks-for-rgb-d</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'term': 'Salient object detection', 'scheme': None, 'label': None}]</td>\n",
       "      <td>Current works either simply distill prior knowledge from the corresponding depth map for handling the RGB-image or blindly fuse color and geometric information to generate the coarse depth-aware representations, hindering the performance of RGB-D...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Convolutional Complex Knowledge Graph Embeddings</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Convolutional Complex Knowledge Graph Embeddings'}</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/convolutional-complex-knowledge-graph'}]</td>\n",
       "      <td>https://paperswithcode.com/paper/convolutional-complex-knowledge-graph</td>\n",
       "      <td>In this paper, we study the problem of learning continuous vector representations of knowledge graphs for predicting missing links. &lt;p&gt;Code: &lt;a href=\"https://github.com/conex-kge/ConEx\"&gt;https://github.com/conex-kge/ConEx&lt;/a&gt;&lt;/p&gt;</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'In this paper, we study the problem of learning continuous vector representations of knowledge graphs for predicting missing link...</td>\n",
       "      <td>https://paperswithcode.com/paper/convolutional-complex-knowledge-graph</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'term': 'Knowledge graph embeddings', 'scheme': None, 'label': None}, {'term': 'Knowledge graphs', 'scheme': None, 'label': None}, {'term': 'Link prediction', 'scheme': None, 'label': None}]</td>\n",
       "      <td>In this paper, we study the problem of learning continuous vector representations of knowledge graphs for predicting missing links. Code: https://github.com/conex-kge/ConEx</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quantum State Tomography with Conditional Generative Adversarial Networks</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Quantum State Tomography with Conditional Generative Adversarial Networks'}</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/quantum-state-tomography-with-conditional'}]</td>\n",
       "      <td>https://paperswithcode.com/paper/quantum-state-tomography-with-conditional</td>\n",
       "      <td>We augment a CGAN with custom neural-network layers that enable conversion of output from any standard neural network into a physical density matrix. &lt;p&gt;Code: &lt;a href=\"https://github.com/quantshah/qst-cgan\"&gt;https://github.com/quantshah/qst-cgan&lt;/...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'We augment a CGAN with custom neural-network layers that enable conversion of output from any standard neural network into a phys...</td>\n",
       "      <td>https://paperswithcode.com/paper/quantum-state-tomography-with-conditional</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'term': 'Quantum state tomography', 'scheme': None, 'label': None}]</td>\n",
       "      <td>We augment a CGAN with custom neural-network layers that enable conversion of output from any standard neural network into a physical density matrix. Code: https://github.com/quantshah/qst-cgan</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Runtimeerror inferencing model on kaggle</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://www.reddit.com/r/kaggle/.rss', 'value': 'Runtimeerror inferencing model on kaggle'}</td>\n",
       "      <td>[{'href': 'https://www.reddit.com/r/kaggle/comments/hom9u0/runtimeerror_inferencing_model_on_kaggle/', 'rel': 'alternate', 'type': 'text/html'}]</td>\n",
       "      <td>https://www.reddit.com/r/kaggle/comments/hom9u0/runtimeerror_inferencing_model_on_kaggle/</td>\n",
       "      <td>&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I trained a model using object detection API (tensorflow) and saved the corresponding Inference graph file on drive (.pb file) I was able to perform Inference on colab but not on kaggle it shows the following err...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/kaggle/t3_hom9u0</td>\n",
       "      <td>True</td>\n",
       "      <td>[{'term': 'kaggle', 'scheme': None, 'label': 'r/kaggle'}]</td>\n",
       "      <td>I trained a model using object detection API (tensorflow) and saved the corresponding Inference graph file on drive (.pb file) I was able to perform Inference on colab but not on kaggle it shows the following error. The session graph is empty.Add...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'name': '/u/bjain1', 'href': 'https://www.reddit.com/user/bjain1'}]</td>\n",
       "      <td>/u/bjain1</td>\n",
       "      <td>{'name': '/u/bjain1', 'href': 'https://www.reddit.com/user/bjain1'}</td>\n",
       "      <td>2020-07-10T10:00:56+00:00</td>\n",
       "      <td>(2020, 7, 10, 10, 0, 56, 4, 192, 0)</td>\n",
       "      <td>[{'type': 'text/html', 'language': None, 'base': 'https://www.reddit.com/r/kaggle/.rss', 'value': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I trained a model using object detection API (tensorflow) and saved the corresponding Inference graph file on dri...</td>\n",
       "      <td>https://www.reddit.com/user/bjain1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>My first notebook</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://www.reddit.com/r/kaggle/.rss', 'value': 'My first notebook'}</td>\n",
       "      <td>[{'href': 'https://www.reddit.com/r/kaggle/comments/hnb83d/my_first_notebook/', 'rel': 'alternate', 'type': 'text/html'}]</td>\n",
       "      <td>https://www.reddit.com/r/kaggle/comments/hnb83d/my_first_notebook/</td>\n",
       "      <td>&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I published my first Kaggle notebook &amp;quot;How to annotate your image dataset effectively&amp;quot;. I am pretty new to Kaggle so it would be great, if you guys take the time to actually visit the kernel and upvote i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/kaggle/t3_hnb83d</td>\n",
       "      <td>True</td>\n",
       "      <td>[{'term': 'kaggle', 'scheme': None, 'label': 'r/kaggle'}]</td>\n",
       "      <td>I published my first Kaggle notebook \"How to annotate your image dataset effectively\". I am pretty new to Kaggle so it would be great, if you guys take the time to actually visit the kernel and upvote it to help me get a wider reach on Kaggle , a...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'name': '/u/dee_tee_', 'href': 'https://www.reddit.com/user/dee_tee_'}]</td>\n",
       "      <td>/u/dee_tee_</td>\n",
       "      <td>{'name': '/u/dee_tee_', 'href': 'https://www.reddit.com/user/dee_tee_'}</td>\n",
       "      <td>2020-07-08T05:24:54+00:00</td>\n",
       "      <td>(2020, 7, 8, 5, 24, 54, 2, 190, 0)</td>\n",
       "      <td>[{'type': 'text/html', 'language': None, 'base': 'https://www.reddit.com/r/kaggle/.rss', 'value': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I published my first Kaggle notebook &amp;quot;How to annotate your image dataset effectively&amp;quot;. I am pretty new ...</td>\n",
       "      <td>https://www.reddit.com/user/dee_tee_</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Should i start withvthe kaggle problems or first finish the course?</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://www.reddit.com/r/kaggle/.rss', 'value': 'Should i start withvthe kaggle problems or first finish the course?'}</td>\n",
       "      <td>[{'href': 'https://www.reddit.com/r/kaggle/comments/hn26oe/should_i_start_withvthe_kaggle_problems_or_first/', 'rel': 'alternate', 'type': 'text/html'}]</td>\n",
       "      <td>https://www.reddit.com/r/kaggle/comments/hn26oe/should_i_start_withvthe_kaggle_problems_or_first/</td>\n",
       "      <td>&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been thinking of getting into kaggle for a long time but cant because i know nothing about making models and all. I have done programming with c++ for quite a while and had recently started with python for...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/kaggle/t3_hn26oe</td>\n",
       "      <td>True</td>\n",
       "      <td>[{'term': 'kaggle', 'scheme': None, 'label': 'r/kaggle'}]</td>\n",
       "      <td>I have been thinking of getting into kaggle for a long time but cant because i know nothing about making models and all. I have done programming with c++ for quite a while and had recently started with python for the same intension. I decided to ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'name': '/u/Mkrsharma', 'href': 'https://www.reddit.com/user/Mkrsharma'}]</td>\n",
       "      <td>/u/Mkrsharma</td>\n",
       "      <td>{'name': '/u/Mkrsharma', 'href': 'https://www.reddit.com/user/Mkrsharma'}</td>\n",
       "      <td>2020-07-07T20:16:28+00:00</td>\n",
       "      <td>(2020, 7, 7, 20, 16, 28, 1, 189, 0)</td>\n",
       "      <td>[{'type': 'text/html', 'language': None, 'base': 'https://www.reddit.com/r/kaggle/.rss', 'value': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been thinking of getting into kaggle for a long time but cant because i know nothing about making models a...</td>\n",
       "      <td>https://www.reddit.com/user/Mkrsharma</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>How i won a kaggle competition</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://www.reddit.com/r/kaggle/.rss', 'value': 'How i won a kaggle competition'}</td>\n",
       "      <td>[{'href': 'https://www.reddit.com/r/kaggle/comments/hmkshm/how_i_won_a_kaggle_competition/', 'rel': 'alternate', 'type': 'text/html'}]</td>\n",
       "      <td>https://www.reddit.com/r/kaggle/comments/hmkshm/how_i_won_a_kaggle_competition/</td>\n",
       "      <td>&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, everyone. This is my first post on medium sharing the tips and tricks that help me to win a kaggle competition. I hope this is helpful for your upcoming challenge.&lt;/p&gt; &lt;p&gt;&lt;a href=\"https://medium.com/@outiscjh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/kaggle/t3_hmkshm</td>\n",
       "      <td>True</td>\n",
       "      <td>[{'term': 'kaggle', 'scheme': None, 'label': 'r/kaggle'}]</td>\n",
       "      <td>Hi, everyone. This is my first post on medium sharing the tips and tricks that help me to win a kaggle competition. I hope this is helpful for your upcoming challenge. https://medium.com/@outiscjh/how-to-win-a-kaggle-classification-competition-bc...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'name': '/u/eistint', 'href': 'https://www.reddit.com/user/eistint'}]</td>\n",
       "      <td>/u/eistint</td>\n",
       "      <td>{'name': '/u/eistint', 'href': 'https://www.reddit.com/user/eistint'}</td>\n",
       "      <td>2020-07-07T01:10:39+00:00</td>\n",
       "      <td>(2020, 7, 7, 1, 10, 39, 1, 189, 0)</td>\n",
       "      <td>[{'type': 'text/html', 'language': None, 'base': 'https://www.reddit.com/r/kaggle/.rss', 'value': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, everyone. This is my first post on medium sharing the tips and tricks that help me to win a kaggle competitio...</td>\n",
       "      <td>https://www.reddit.com/user/eistint</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Tao Of ML: Interview With Kaggle Master Oleg Yaroshevskiy</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://www.reddit.com/r/kaggle/.rss', 'value': 'Tao Of ML: Interview With Kaggle Master Oleg Yaroshevskiy'}</td>\n",
       "      <td>[{'href': 'https://www.reddit.com/r/kaggle/comments/hmofhz/tao_of_ml_interview_with_kaggle_master_oleg/', 'rel': 'alternate', 'type': 'text/html'}]</td>\n",
       "      <td>https://www.reddit.com/r/kaggle/comments/hmofhz/tao_of_ml_interview_with_kaggle_master_oleg/</td>\n",
       "      <td>&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://analyticsindiamag.com/kaggle-master-interview-oleg/\"&gt;https://analyticsindiamag.com/kaggle-master-interview-oleg/&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=\"https://www.reddit....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/kaggle/t3_hmofhz</td>\n",
       "      <td>True</td>\n",
       "      <td>[{'term': 'kaggle', 'scheme': None, 'label': 'r/kaggle'}]</td>\n",
       "      <td>https://analyticsindiamag.com/kaggle-master-interview-oleg/    submitted by    /u/analyticsindiam   [link] [comments]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'name': '/u/analyticsindiam', 'href': 'https://www.reddit.com/user/analyticsindiam'}]</td>\n",
       "      <td>/u/analyticsindiam</td>\n",
       "      <td>{'name': '/u/analyticsindiam', 'href': 'https://www.reddit.com/user/analyticsindiam'}</td>\n",
       "      <td>2020-07-07T05:21:23+00:00</td>\n",
       "      <td>(2020, 7, 7, 5, 21, 23, 1, 189, 0)</td>\n",
       "      <td>[{'type': 'text/html', 'language': None, 'base': 'https://www.reddit.com/r/kaggle/.rss', 'value': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://analyticsindiamag.com/kaggle-master-interview-oleg/\"&gt;https://analyticsindiamag.com/kaggle-master...</td>\n",
       "      <td>https://www.reddit.com/user/analyticsindiam</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                    title  \\\n",
       "0   I2L-MeshNet: Image-to-Lixel Prediction Network for Accurate 3D Human Pose and Mesh Estimation from a Single RGB Image   \n",
       "1                                              Polysemy Deciphering Network for Robust Human-Object Interaction Detection   \n",
       "2                                                        Cascade Graph Neural Networks for RGB-D Salient Object Detection   \n",
       "3                                                                        Convolutional Complex Knowledge Graph Embeddings   \n",
       "4                                               Quantum State Tomography with Conditional Generative Adversarial Networks   \n",
       "..                                                                                                                    ...   \n",
       "20                                                                               Runtimeerror inferencing model on kaggle   \n",
       "21                                                                                                      My first notebook   \n",
       "22                                                    Should i start withvthe kaggle problems or first finish the course?   \n",
       "23                                                                                         How i won a kaggle competition   \n",
       "24                                                              Tao Of ML: Interview With Kaggle Master Oleg Yaroshevskiy   \n",
       "\n",
       "                                                                                                                                                                                                                                     title_detail  \\\n",
       "0   {'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'I2L-MeshNet: Image-to-Lixel Prediction Network for Accurate 3D Human Pose and Mesh Estimation from a Single RGB Image'}   \n",
       "1                                              {'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Polysemy Deciphering Network for Robust Human-Object Interaction Detection'}   \n",
       "2                                                        {'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Cascade Graph Neural Networks for RGB-D Salient Object Detection'}   \n",
       "3                                                                        {'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Convolutional Complex Knowledge Graph Embeddings'}   \n",
       "4                                               {'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Quantum State Tomography with Conditional Generative Adversarial Networks'}   \n",
       "..                                                                                                                                                                                                                                            ...   \n",
       "20                                                                                                  {'type': 'text/plain', 'language': None, 'base': 'https://www.reddit.com/r/kaggle/.rss', 'value': 'Runtimeerror inferencing model on kaggle'}   \n",
       "21                                                                                                                         {'type': 'text/plain', 'language': None, 'base': 'https://www.reddit.com/r/kaggle/.rss', 'value': 'My first notebook'}   \n",
       "22                                                                       {'type': 'text/plain', 'language': None, 'base': 'https://www.reddit.com/r/kaggle/.rss', 'value': 'Should i start withvthe kaggle problems or first finish the course?'}   \n",
       "23                                                                                                            {'type': 'text/plain', 'language': None, 'base': 'https://www.reddit.com/r/kaggle/.rss', 'value': 'How i won a kaggle competition'}   \n",
       "24                                                                                 {'type': 'text/plain', 'language': None, 'base': 'https://www.reddit.com/r/kaggle/.rss', 'value': 'Tao Of ML: Interview With Kaggle Master Oleg Yaroshevskiy'}   \n",
       "\n",
       "                                                                                                                                                       links  \\\n",
       "0                      [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/i2l-meshnet-image-to-lixel-prediction-network'}]   \n",
       "1                      [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/polysemy-deciphering-network-for-robust-human'}]   \n",
       "2                            [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/cascade-graph-neural-networks-for-rgb-d'}]   \n",
       "3                              [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/convolutional-complex-knowledge-graph'}]   \n",
       "4                          [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/quantum-state-tomography-with-conditional'}]   \n",
       "..                                                                                                                                                       ...   \n",
       "20          [{'href': 'https://www.reddit.com/r/kaggle/comments/hom9u0/runtimeerror_inferencing_model_on_kaggle/', 'rel': 'alternate', 'type': 'text/html'}]   \n",
       "21                                 [{'href': 'https://www.reddit.com/r/kaggle/comments/hnb83d/my_first_notebook/', 'rel': 'alternate', 'type': 'text/html'}]   \n",
       "22  [{'href': 'https://www.reddit.com/r/kaggle/comments/hn26oe/should_i_start_withvthe_kaggle_problems_or_first/', 'rel': 'alternate', 'type': 'text/html'}]   \n",
       "23                    [{'href': 'https://www.reddit.com/r/kaggle/comments/hmkshm/how_i_won_a_kaggle_competition/', 'rel': 'alternate', 'type': 'text/html'}]   \n",
       "24       [{'href': 'https://www.reddit.com/r/kaggle/comments/hmofhz/tao_of_ml_interview_with_kaggle_master_oleg/', 'rel': 'alternate', 'type': 'text/html'}]   \n",
       "\n",
       "                                                                                                 link  \\\n",
       "0                      https://paperswithcode.com/paper/i2l-meshnet-image-to-lixel-prediction-network   \n",
       "1                      https://paperswithcode.com/paper/polysemy-deciphering-network-for-robust-human   \n",
       "2                            https://paperswithcode.com/paper/cascade-graph-neural-networks-for-rgb-d   \n",
       "3                              https://paperswithcode.com/paper/convolutional-complex-knowledge-graph   \n",
       "4                          https://paperswithcode.com/paper/quantum-state-tomography-with-conditional   \n",
       "..                                                                                                ...   \n",
       "20          https://www.reddit.com/r/kaggle/comments/hom9u0/runtimeerror_inferencing_model_on_kaggle/   \n",
       "21                                 https://www.reddit.com/r/kaggle/comments/hnb83d/my_first_notebook/   \n",
       "22  https://www.reddit.com/r/kaggle/comments/hn26oe/should_i_start_withvthe_kaggle_problems_or_first/   \n",
       "23                    https://www.reddit.com/r/kaggle/comments/hmkshm/how_i_won_a_kaggle_competition/   \n",
       "24       https://www.reddit.com/r/kaggle/comments/hmofhz/tao_of_ml_interview_with_kaggle_master_oleg/   \n",
       "\n",
       "                                                                                                                                                                                                                                                      summary  \\\n",
       "0   Most of the previous image-based 3D human pose and mesh estimation methods estimate parameters of the human mesh model from an input image. <p>Code: <a href=\"https://github.com/mks0601/I2L-MeshNet_RELEASE\">https://github.com/mks0601/I2L-MeshNet_R...   \n",
       "1   To address this issue, in this paper, we propose a novel Polysemy Deciphering Network (PD-Net) that decodes the visual polysemy of verbs for HOI detection in three distinct ways. <p>Code: <a href=\"https://github.com/MuchHair/PD-Net\">https://githu...   \n",
       "2   Current works either simply distill prior knowledge from the corresponding depth map for handling the RGB-image or blindly fuse color and geometric information to generate the coarse depth-aware representations, hindering the performance of RGB-D...   \n",
       "3                        In this paper, we study the problem of learning continuous vector representations of knowledge graphs for predicting missing links. <p>Code: <a href=\"https://github.com/conex-kge/ConEx\">https://github.com/conex-kge/ConEx</a></p>   \n",
       "4   We augment a CGAN with custom neural-network layers that enable conversion of output from any standard neural network into a physical density matrix. <p>Code: <a href=\"https://github.com/quantshah/qst-cgan\">https://github.com/quantshah/qst-cgan</...   \n",
       "..                                                                                                                                                                                                                                                        ...   \n",
       "20  <!-- SC_OFF --><div class=\"md\"><p>I trained a model using object detection API (tensorflow) and saved the corresponding Inference graph file on drive (.pb file) I was able to perform Inference on colab but not on kaggle it shows the following err...   \n",
       "21  <!-- SC_OFF --><div class=\"md\"><p>I published my first Kaggle notebook &quot;How to annotate your image dataset effectively&quot;. I am pretty new to Kaggle so it would be great, if you guys take the time to actually visit the kernel and upvote i...   \n",
       "22  <!-- SC_OFF --><div class=\"md\"><p>I have been thinking of getting into kaggle for a long time but cant because i know nothing about making models and all. I have done programming with c++ for quite a while and had recently started with python for...   \n",
       "23  <!-- SC_OFF --><div class=\"md\"><p>Hi, everyone. This is my first post on medium sharing the tips and tricks that help me to win a kaggle competition. I hope this is helpful for your upcoming challenge.</p> <p><a href=\"https://medium.com/@outiscjh...   \n",
       "24  <!-- SC_OFF --><div class=\"md\"><p><a href=\"https://analyticsindiamag.com/kaggle-master-interview-oleg/\">https://analyticsindiamag.com/kaggle-master-interview-oleg/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href=\"https://www.reddit....   \n",
       "\n",
       "                                                                                                                                                                                                                                               summary_detail  \\\n",
       "0   {'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Most of the previous image-based 3D human pose and mesh estimation methods estimate parameters of the human mesh model from an in...   \n",
       "1   {'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'To address this issue, in this paper, we propose a novel Polysemy Deciphering Network (PD-Net) that decodes the visual polysemy o...   \n",
       "2   {'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Current works either simply distill prior knowledge from the corresponding depth map for handling the RGB-image or blindly fuse c...   \n",
       "3   {'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'In this paper, we study the problem of learning continuous vector representations of knowledge graphs for predicting missing link...   \n",
       "4   {'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'We augment a CGAN with custom neural-network layers that enable conversion of output from any standard neural network into a phys...   \n",
       "..                                                                                                                                                                                                                                                        ...   \n",
       "20                                                                                                                                                                                                                                                        NaN   \n",
       "21                                                                                                                                                                                                                                                        NaN   \n",
       "22                                                                                                                                                                                                                                                        NaN   \n",
       "23                                                                                                                                                                                                                                                        NaN   \n",
       "24                                                                                                                                                                                                                                                        NaN   \n",
       "\n",
       "                                                                                id  \\\n",
       "0   https://paperswithcode.com/paper/i2l-meshnet-image-to-lixel-prediction-network   \n",
       "1   https://paperswithcode.com/paper/polysemy-deciphering-network-for-robust-human   \n",
       "2         https://paperswithcode.com/paper/cascade-graph-neural-networks-for-rgb-d   \n",
       "3           https://paperswithcode.com/paper/convolutional-complex-knowledge-graph   \n",
       "4       https://paperswithcode.com/paper/quantum-state-tomography-with-conditional   \n",
       "..                                                                             ...   \n",
       "20                                       https://www.reddit.com/r/kaggle/t3_hom9u0   \n",
       "21                                       https://www.reddit.com/r/kaggle/t3_hnb83d   \n",
       "22                                       https://www.reddit.com/r/kaggle/t3_hn26oe   \n",
       "23                                       https://www.reddit.com/r/kaggle/t3_hmkshm   \n",
       "24                                       https://www.reddit.com/r/kaggle/t3_hmofhz   \n",
       "\n",
       "   guidislink  \\\n",
       "0       False   \n",
       "1       False   \n",
       "2       False   \n",
       "3       False   \n",
       "4       False   \n",
       "..        ...   \n",
       "20       True   \n",
       "21       True   \n",
       "22       True   \n",
       "23       True   \n",
       "24       True   \n",
       "\n",
       "                                                                                                                                                                                                tags  \\\n",
       "0                                                          [{'term': '3d hand pose estimation', 'scheme': None, 'label': None}, {'term': '3d human pose estimation', 'scheme': None, 'label': None}]   \n",
       "1                                                    [{'term': 'Human-object interaction detection', 'scheme': None, 'label': None}, {'term': 'Scene understanding', 'scheme': None, 'label': None}]   \n",
       "2                                                                                                                              [{'term': 'Salient object detection', 'scheme': None, 'label': None}]   \n",
       "3   [{'term': 'Knowledge graph embeddings', 'scheme': None, 'label': None}, {'term': 'Knowledge graphs', 'scheme': None, 'label': None}, {'term': 'Link prediction', 'scheme': None, 'label': None}]   \n",
       "4                                                                                                                              [{'term': 'Quantum state tomography', 'scheme': None, 'label': None}]   \n",
       "..                                                                                                                                                                                               ...   \n",
       "20                                                                                                                                         [{'term': 'kaggle', 'scheme': None, 'label': 'r/kaggle'}]   \n",
       "21                                                                                                                                         [{'term': 'kaggle', 'scheme': None, 'label': 'r/kaggle'}]   \n",
       "22                                                                                                                                         [{'term': 'kaggle', 'scheme': None, 'label': 'r/kaggle'}]   \n",
       "23                                                                                                                                         [{'term': 'kaggle', 'scheme': None, 'label': 'r/kaggle'}]   \n",
       "24                                                                                                                                         [{'term': 'kaggle', 'scheme': None, 'label': 'r/kaggle'}]   \n",
       "\n",
       "                                                                                                                                                                                                                                                         text  \\\n",
       "0                                                            Most of the previous image-based 3D human pose and mesh estimation methods estimate parameters of the human mesh model from an input image. Code: https://github.com/mks0601/I2L-MeshNet_RELEASE   \n",
       "1                                 To address this issue, in this paper, we propose a novel Polysemy Deciphering Network (PD-Net) that decodes the visual polysemy of verbs for HOI detection in three distinct ways. Code: https://github.com/MuchHair/PD-Net   \n",
       "2   Current works either simply distill prior knowledge from the corresponding depth map for handling the RGB-image or blindly fuse color and geometric information to generate the coarse depth-aware representations, hindering the performance of RGB-D...   \n",
       "3                                                                                In this paper, we study the problem of learning continuous vector representations of knowledge graphs for predicting missing links. Code: https://github.com/conex-kge/ConEx   \n",
       "4                                                           We augment a CGAN with custom neural-network layers that enable conversion of output from any standard neural network into a physical density matrix. Code: https://github.com/quantshah/qst-cgan   \n",
       "..                                                                                                                                                                                                                                                        ...   \n",
       "20  I trained a model using object detection API (tensorflow) and saved the corresponding Inference graph file on drive (.pb file) I was able to perform Inference on colab but not on kaggle it shows the following error. The session graph is empty.Add...   \n",
       "21  I published my first Kaggle notebook \"How to annotate your image dataset effectively\". I am pretty new to Kaggle so it would be great, if you guys take the time to actually visit the kernel and upvote it to help me get a wider reach on Kaggle , a...   \n",
       "22  I have been thinking of getting into kaggle for a long time but cant because i know nothing about making models and all. I have done programming with c++ for quite a while and had recently started with python for the same intension. I decided to ...   \n",
       "23  Hi, everyone. This is my first post on medium sharing the tips and tricks that help me to win a kaggle competition. I hope this is helpful for your upcoming challenge. https://medium.com/@outiscjh/how-to-win-a-kaggle-classification-competition-bc...   \n",
       "24                                                                                                                                      https://analyticsindiamag.com/kaggle-master-interview-oleg/    submitted by    /u/analyticsindiam   [link] [comments]   \n",
       "\n",
       "    ... published_parsed comments  \\\n",
       "0   ...              NaN      NaN   \n",
       "1   ...              NaN      NaN   \n",
       "2   ...              NaN      NaN   \n",
       "3   ...              NaN      NaN   \n",
       "4   ...              NaN      NaN   \n",
       "..  ...              ...      ...   \n",
       "20  ...              NaN      NaN   \n",
       "21  ...              NaN      NaN   \n",
       "22  ...              NaN      NaN   \n",
       "23  ...              NaN      NaN   \n",
       "24  ...              NaN      NaN   \n",
       "\n",
       "                                                                                    authors  \\\n",
       "0                                                                                       NaN   \n",
       "1                                                                                       NaN   \n",
       "2                                                                                       NaN   \n",
       "3                                                                                       NaN   \n",
       "4                                                                                       NaN   \n",
       "..                                                                                      ...   \n",
       "20                    [{'name': '/u/bjain1', 'href': 'https://www.reddit.com/user/bjain1'}]   \n",
       "21                [{'name': '/u/dee_tee_', 'href': 'https://www.reddit.com/user/dee_tee_'}]   \n",
       "22              [{'name': '/u/Mkrsharma', 'href': 'https://www.reddit.com/user/Mkrsharma'}]   \n",
       "23                  [{'name': '/u/eistint', 'href': 'https://www.reddit.com/user/eistint'}]   \n",
       "24  [{'name': '/u/analyticsindiam', 'href': 'https://www.reddit.com/user/analyticsindiam'}]   \n",
       "\n",
       "                author  \\\n",
       "0                  NaN   \n",
       "1                  NaN   \n",
       "2                  NaN   \n",
       "3                  NaN   \n",
       "4                  NaN   \n",
       "..                 ...   \n",
       "20           /u/bjain1   \n",
       "21         /u/dee_tee_   \n",
       "22        /u/Mkrsharma   \n",
       "23          /u/eistint   \n",
       "24  /u/analyticsindiam   \n",
       "\n",
       "                                                                            author_detail  \\\n",
       "0                                                                                     NaN   \n",
       "1                                                                                     NaN   \n",
       "2                                                                                     NaN   \n",
       "3                                                                                     NaN   \n",
       "4                                                                                     NaN   \n",
       "..                                                                                    ...   \n",
       "20                    {'name': '/u/bjain1', 'href': 'https://www.reddit.com/user/bjain1'}   \n",
       "21                {'name': '/u/dee_tee_', 'href': 'https://www.reddit.com/user/dee_tee_'}   \n",
       "22              {'name': '/u/Mkrsharma', 'href': 'https://www.reddit.com/user/Mkrsharma'}   \n",
       "23                  {'name': '/u/eistint', 'href': 'https://www.reddit.com/user/eistint'}   \n",
       "24  {'name': '/u/analyticsindiam', 'href': 'https://www.reddit.com/user/analyticsindiam'}   \n",
       "\n",
       "                      updated                       updated_parsed  \\\n",
       "0                         NaN                                  NaN   \n",
       "1                         NaN                                  NaN   \n",
       "2                         NaN                                  NaN   \n",
       "3                         NaN                                  NaN   \n",
       "4                         NaN                                  NaN   \n",
       "..                        ...                                  ...   \n",
       "20  2020-07-10T10:00:56+00:00  (2020, 7, 10, 10, 0, 56, 4, 192, 0)   \n",
       "21  2020-07-08T05:24:54+00:00   (2020, 7, 8, 5, 24, 54, 2, 190, 0)   \n",
       "22  2020-07-07T20:16:28+00:00  (2020, 7, 7, 20, 16, 28, 1, 189, 0)   \n",
       "23  2020-07-07T01:10:39+00:00   (2020, 7, 7, 1, 10, 39, 1, 189, 0)   \n",
       "24  2020-07-07T05:21:23+00:00   (2020, 7, 7, 5, 21, 23, 1, 189, 0)   \n",
       "\n",
       "                                                                                                                                                                                                                                                      content  \\\n",
       "0                                                                                                                                                                                                                                                         NaN   \n",
       "1                                                                                                                                                                                                                                                         NaN   \n",
       "2                                                                                                                                                                                                                                                         NaN   \n",
       "3                                                                                                                                                                                                                                                         NaN   \n",
       "4                                                                                                                                                                                                                                                         NaN   \n",
       "..                                                                                                                                                                                                                                                        ...   \n",
       "20  [{'type': 'text/html', 'language': None, 'base': 'https://www.reddit.com/r/kaggle/.rss', 'value': '<!-- SC_OFF --><div class=\"md\"><p>I trained a model using object detection API (tensorflow) and saved the corresponding Inference graph file on dri...   \n",
       "21  [{'type': 'text/html', 'language': None, 'base': 'https://www.reddit.com/r/kaggle/.rss', 'value': '<!-- SC_OFF --><div class=\"md\"><p>I published my first Kaggle notebook &quot;How to annotate your image dataset effectively&quot;. I am pretty new ...   \n",
       "22  [{'type': 'text/html', 'language': None, 'base': 'https://www.reddit.com/r/kaggle/.rss', 'value': '<!-- SC_OFF --><div class=\"md\"><p>I have been thinking of getting into kaggle for a long time but cant because i know nothing about making models a...   \n",
       "23  [{'type': 'text/html', 'language': None, 'base': 'https://www.reddit.com/r/kaggle/.rss', 'value': '<!-- SC_OFF --><div class=\"md\"><p>Hi, everyone. This is my first post on medium sharing the tips and tricks that help me to win a kaggle competitio...   \n",
       "24  [{'type': 'text/html', 'language': None, 'base': 'https://www.reddit.com/r/kaggle/.rss', 'value': '<!-- SC_OFF --><div class=\"md\"><p><a href=\"https://analyticsindiamag.com/kaggle-master-interview-oleg/\">https://analyticsindiamag.com/kaggle-master...   \n",
       "\n",
       "                                           href media_thumbnail  \n",
       "0                                           NaN             NaN  \n",
       "1                                           NaN             NaN  \n",
       "2                                           NaN             NaN  \n",
       "3                                           NaN             NaN  \n",
       "4                                           NaN             NaN  \n",
       "..                                          ...             ...  \n",
       "20           https://www.reddit.com/user/bjain1             NaN  \n",
       "21         https://www.reddit.com/user/dee_tee_             NaN  \n",
       "22        https://www.reddit.com/user/Mkrsharma             NaN  \n",
       "23          https://www.reddit.com/user/eistint             NaN  \n",
       "24  https://www.reddit.com/user/analyticsindiam             NaN  \n",
       "\n",
       "[295 rows x 21 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_df[['title', 'summary', 'link']].reset_index().join(results_df).to_csv('feed_topics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                                                                               I2L-MeshNet: Image-to-Lixel Prediction Network for Accurate 3D Human Pose and Mesh Estimation from a Single RGB Image\n",
       "text     Most of the previous image-based 3D human pose and mesh estimation methods estimate parameters of the human mesh model from an input image. Code: https://github.com/mks0601/I2L-MeshNet_RELEASE\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_article[['title', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [c for c, __ in results]\n",
    "scores = [score for __, score in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(scores, categories)\n",
    "sns.despine(left=True, bottom=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
