{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp haystack_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/16/2020 13:01:42 - INFO - transformers.file_utils -   PyTorch version 1.5.0+cu101 available.\n",
      "08/16/2020 13:01:43 - INFO - transformers.file_utils -   TensorFlow version 2.1.0 available.\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "from nltk import tokenize\n",
    "from operator import itemgetter\n",
    "\n",
    "from haystack.database.elasticsearch import ElasticsearchDocumentStore\n",
    "from haystack.database.memory import InMemoryDocumentStore\n",
    "\n",
    "from haystack.retriever.dense import EmbeddingRetriever\n",
    "from pytorch_hackathon import rss_feeds\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sns.light_palette(\"green\", as_cmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kuba/Projects/pytorch_hackathon\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feeds.txt  topics.txt  zsl_feed_results.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rss_feed_urls = list(pd.read_table('data/feeds.txt', header=None).iloc[:,0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:07<00:00,  2.11it/s]\n",
      "/home/kuba/Projects/pytorch_hackathon/pytorch_hackathon/rss_feeds.py:63: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 63 of the file /home/kuba/Projects/pytorch_hackathon/pytorch_hackathon/rss_feeds.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  feed_df['text'] = feed_df['summary'].apply(lambda s: bs4.BeautifulSoup(s).text)\n"
     ]
    }
   ],
   "source": [
    "feed_df = rss_feeds.get_feed_df(rss_feed_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print = pprint.PrettyPrinter(indent=2).pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title_detail</th>\n",
       "      <th>links</th>\n",
       "      <th>link</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_detail</th>\n",
       "      <th>id</th>\n",
       "      <th>guidislink</th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "      <th>...</th>\n",
       "      <th>published_parsed</th>\n",
       "      <th>comments</th>\n",
       "      <th>authors</th>\n",
       "      <th>author</th>\n",
       "      <th>author_detail</th>\n",
       "      <th>updated</th>\n",
       "      <th>updated_parsed</th>\n",
       "      <th>content</th>\n",
       "      <th>href</th>\n",
       "      <th>media_thumbnail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hybrid Dynamic-static Context-aware Attention Network for Action Assessment in Long Videos</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/p...</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/hybrid-dyna...</td>\n",
       "      <td>https://paperswithcode.com/paper/hybrid-dynamic-static-context-aware-attention</td>\n",
       "      <td>However, most existing works focus only on video dynamic information (i. e., motion information)...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pw...</td>\n",
       "      <td>https://paperswithcode.com/paper/hybrid-dynamic-static-context-aware-attention</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'term': 'Action quality assessment', 'scheme': None, 'label': None}]</td>\n",
       "      <td>However, most existing works focus only on video dynamic information (i. e., motion information)...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Predicting Visual Overlap of Images Through Interpretable Non-Metric Box Embeddings</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/p...</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/predicting-...</td>\n",
       "      <td>https://paperswithcode.com/paper/predicting-visual-overlap-of-images-through</td>\n",
       "      <td>Even when this is a known scene, the answer typically requires an expensive search across scale ...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pw...</td>\n",
       "      <td>https://paperswithcode.com/paper/predicting-visual-overlap-of-images-through</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Even when this is a known scene, the answer typically requires an expensive search across scale ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Statistical Evaluation of Anomaly Detectors for Sequences</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/p...</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/statistical...</td>\n",
       "      <td>https://paperswithcode.com/paper/statistical-evaluation-of-anomaly-detectors</td>\n",
       "      <td>Although precision and recall are standard performance measures for anomaly detection, their sta...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pw...</td>\n",
       "      <td>https://paperswithcode.com/paper/statistical-evaluation-of-anomaly-detectors</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'term': 'Anomaly detection', 'scheme': None, 'label': None}]</td>\n",
       "      <td>Although precision and recall are standard performance measures for anomaly detection, their sta...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On failures of RGB cameras and their effects in autonomous driving applications</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/p...</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/on-failures...</td>\n",
       "      <td>https://paperswithcode.com/paper/on-failures-of-rgb-cameras-and-their-effects</td>\n",
       "      <td>RGB cameras are arguably one of the most relevant sensors for autonomous driving applications. &lt;...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pw...</td>\n",
       "      <td>https://paperswithcode.com/paper/on-failures-of-rgb-cameras-and-their-effects</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'term': 'Autonomous driving', 'scheme': None, 'label': None}]</td>\n",
       "      <td>RGB cameras are arguably one of the most relevant sensors for autonomous driving applications. C...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Contextual Diversity for Active Learning</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/p...</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/contextual-...</td>\n",
       "      <td>https://paperswithcode.com/paper/contextual-diversity-for-active-learning</td>\n",
       "      <td>Contextual Diversity (CD) hinges on a crucial observation that the probability vector predicted ...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pw...</td>\n",
       "      <td>https://paperswithcode.com/paper/contextual-diversity-for-active-learning</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'term': 'Active learning', 'scheme': None, 'label': None}, {'term': 'Image classification', 's...</td>\n",
       "      <td>Contextual Diversity (CD) hinges on a crucial observation that the probability vector predicted ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        title  \\\n",
       "0  Hybrid Dynamic-static Context-aware Attention Network for Action Assessment in Long Videos   \n",
       "1         Predicting Visual Overlap of Images Through Interpretable Non-Metric Box Embeddings   \n",
       "2                                   Statistical Evaluation of Anomaly Detectors for Sequences   \n",
       "3             On failures of RGB cameras and their effects in autonomous driving applications   \n",
       "4                                                    Contextual Diversity for Active Learning   \n",
       "\n",
       "                                                                                          title_detail  \\\n",
       "0  {'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/p...   \n",
       "1  {'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/p...   \n",
       "2  {'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/p...   \n",
       "3  {'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/p...   \n",
       "4  {'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/p...   \n",
       "\n",
       "                                                                                                 links  \\\n",
       "0  [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/hybrid-dyna...   \n",
       "1  [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/predicting-...   \n",
       "2  [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/statistical...   \n",
       "3  [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/on-failures...   \n",
       "4  [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/contextual-...   \n",
       "\n",
       "                                                                             link  \\\n",
       "0  https://paperswithcode.com/paper/hybrid-dynamic-static-context-aware-attention   \n",
       "1    https://paperswithcode.com/paper/predicting-visual-overlap-of-images-through   \n",
       "2    https://paperswithcode.com/paper/statistical-evaluation-of-anomaly-detectors   \n",
       "3   https://paperswithcode.com/paper/on-failures-of-rgb-cameras-and-their-effects   \n",
       "4       https://paperswithcode.com/paper/contextual-diversity-for-active-learning   \n",
       "\n",
       "                                                                                               summary  \\\n",
       "0  However, most existing works focus only on video dynamic information (i. e., motion information)...   \n",
       "1  Even when this is a known scene, the answer typically requires an expensive search across scale ...   \n",
       "2  Although precision and recall are standard performance measures for anomaly detection, their sta...   \n",
       "3  RGB cameras are arguably one of the most relevant sensors for autonomous driving applications. <...   \n",
       "4  Contextual Diversity (CD) hinges on a crucial observation that the probability vector predicted ...   \n",
       "\n",
       "                                                                                        summary_detail  \\\n",
       "0  {'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pw...   \n",
       "1  {'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pw...   \n",
       "2  {'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pw...   \n",
       "3  {'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pw...   \n",
       "4  {'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pw...   \n",
       "\n",
       "                                                                               id  \\\n",
       "0  https://paperswithcode.com/paper/hybrid-dynamic-static-context-aware-attention   \n",
       "1    https://paperswithcode.com/paper/predicting-visual-overlap-of-images-through   \n",
       "2    https://paperswithcode.com/paper/statistical-evaluation-of-anomaly-detectors   \n",
       "3   https://paperswithcode.com/paper/on-failures-of-rgb-cameras-and-their-effects   \n",
       "4       https://paperswithcode.com/paper/contextual-diversity-for-active-learning   \n",
       "\n",
       "  guidislink  \\\n",
       "0      False   \n",
       "1      False   \n",
       "2      False   \n",
       "3      False   \n",
       "4      False   \n",
       "\n",
       "                                                                                                  tags  \\\n",
       "0                               [{'term': 'Action quality assessment', 'scheme': None, 'label': None}]   \n",
       "1                                                                                                  NaN   \n",
       "2                                       [{'term': 'Anomaly detection', 'scheme': None, 'label': None}]   \n",
       "3                                      [{'term': 'Autonomous driving', 'scheme': None, 'label': None}]   \n",
       "4  [{'term': 'Active learning', 'scheme': None, 'label': None}, {'term': 'Image classification', 's...   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  However, most existing works focus only on video dynamic information (i. e., motion information)...   \n",
       "1  Even when this is a known scene, the answer typically requires an expensive search across scale ...   \n",
       "2  Although precision and recall are standard performance measures for anomaly detection, their sta...   \n",
       "3  RGB cameras are arguably one of the most relevant sensors for autonomous driving applications. C...   \n",
       "4  Contextual Diversity (CD) hinges on a crucial observation that the probability vector predicted ...   \n",
       "\n",
       "   ... published_parsed comments authors author author_detail updated  \\\n",
       "0  ...              NaN      NaN     NaN    NaN           NaN     NaN   \n",
       "1  ...              NaN      NaN     NaN    NaN           NaN     NaN   \n",
       "2  ...              NaN      NaN     NaN    NaN           NaN     NaN   \n",
       "3  ...              NaN      NaN     NaN    NaN           NaN     NaN   \n",
       "4  ...              NaN      NaN     NaN    NaN           NaN     NaN   \n",
       "\n",
       "  updated_parsed content href media_thumbnail  \n",
       "0            NaN     NaN  NaN             NaN  \n",
       "1            NaN     NaN  NaN             NaN  \n",
       "2            NaN     NaN  NaN             NaN  \n",
       "3            NaN     NaN  NaN             NaN  \n",
       "4            NaN     NaN  NaN             NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "\n",
    "class Searcher:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name,\n",
    "        text_col,\n",
    "        use_gpu,\n",
    "        max_document_length=256,\n",
    "        quantize_model=True,\n",
    "        document_store_cls=InMemoryDocumentStore\n",
    "    ):\n",
    "        self.text_col = text_col\n",
    "        self.embedding_col = text_col + '_emb'\n",
    "        self.max_document_length = max_document_length\n",
    "        self.model_name = model_name\n",
    "        self.document_store = document_store_cls(\n",
    "            embedding_field=self.embedding_col,\n",
    "        )\n",
    "        self.retriever = self._setup_retriever(use_gpu, quantize_model)\n",
    "\n",
    "    def _setup_retriever(self, use_gpu, quantize_model):\n",
    "        retriever = EmbeddingRetriever(\n",
    "            document_store=self.document_store,\n",
    "            embedding_model=self.model_name,\n",
    "            use_gpu=use_gpu)\n",
    "        if not use_gpu and quantize_model:\n",
    "            self.set_quantized_model(retriever)\n",
    "            \n",
    "        return retriever\n",
    "\n",
    "    def add_texts(\n",
    "        self,\n",
    "        df\n",
    "    ):\n",
    "        truncated_texts = [\n",
    "            ' '.join(tokenize.wordpunct_tokenize(text)[:self.max_document_length])\n",
    "            for text in df[self.text_col] \n",
    "        ]\n",
    "        article_embeddings = self.retriever.embed_queries(\n",
    "            texts=truncated_texts\n",
    "        )\n",
    "\n",
    "        df[self.embedding_col] = article_embeddings\n",
    "        self.document_store.write_documents(df.to_dict(orient='records'))\n",
    "    \n",
    "    @classmethod\n",
    "    def set_quantized_model(cls, retriever):\n",
    "        quantized_model = torch.quantization.quantize_dynamic(\n",
    "            retriever.embedding_model.model,\n",
    "            {torch.nn.Linear}, dtype=torch.qint8\n",
    "        )\n",
    "        retriever.embedding_model.model = quantized_model\n",
    "        \n",
    "    @classmethod \n",
    "    def sigmoid(cls, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    @classmethod\n",
    "    def doc_to_dict(cls, doc):\n",
    "        d = {}\n",
    "        d['text'] = doc.text\n",
    "        d['title'] = doc.meta['title']\n",
    "        d['score'] = doc.query_score\n",
    "        return d\n",
    "\n",
    "    def get_topic_score_df(self, raw_results, topic_strings):\n",
    "        topic_query_strings = [\n",
    "            'text is about {}'.format(topic)\n",
    "            for topic in topic_strings\n",
    "        ]\n",
    "\n",
    "        results = [\n",
    "            self.doc_to_dict(doc)\n",
    "            for doc in raw_results \n",
    "        ]\n",
    "        result_embeddings = np.array([\n",
    "            doc.meta['text_emb']\n",
    "            for doc in raw_results\n",
    "        ]).astype('float32')\n",
    "        topic_query_embeddings = np.array(self.retriever.embed_passages(\n",
    "            list(topic_strings)\n",
    "        )).astype('float32')\n",
    "\n",
    "        scores_df = pd.DataFrame({})\n",
    "        scores_df['title'] = list(map(itemgetter('title'), results))\n",
    "        scores_df['text'] = list(map(itemgetter('text'), results))\n",
    "\n",
    "        scores = pd.DataFrame(metrics.pairwise.cosine_similarity(\n",
    "            result_embeddings,\n",
    "            topic_query_embeddings\n",
    "        ))\n",
    "        scores.columns = topic_strings\n",
    "\n",
    "        scores_df = pd.concat(\n",
    "            [scores_df, self.sigmoid(scores)],\n",
    "            axis=1\n",
    "        )\n",
    "        return scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"deepset/sentence_bert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/16/2020 13:01:52 - INFO - haystack.retriever.dense -   Init retriever using embeddings of model deepset/sentence_bert\n",
      "08/16/2020 13:01:52 - INFO - farm.utils -   device: cuda n_gpu: 1, distributed training: False, automatic mixed precision training: None\n",
      "08/16/2020 13:01:52 - INFO - farm.infer -   Could not find `deepset/sentence_bert` locally. Try to download from model hub ...\n",
      "08/16/2020 13:01:53 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/deepset/sentence_bert/pytorch_model.bin from cache at /home/kuba/.cache/torch/transformers/fa9d12cb00cd5a31f5a5367f58d242199473a6deb02c51380681ade7bf33c713.4948a08b5d844db1ecda79f6e7f47643f0175f2c030d48ce8b3beee3c6bd6012\n",
      "08/16/2020 13:01:54 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing BertModel.\n",
      "\n",
      "08/16/2020 13:01:54 - INFO - transformers.modeling_utils -   All the weights of BertModel were initialized from the model checkpoint at deepset/sentence_bert.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "08/16/2020 13:01:54 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n",
      "08/16/2020 13:01:58 - INFO - farm.modeling.tokenization -   Loading tokenizer of type 'BertTokenizer'\n",
      "08/16/2020 13:01:58 - INFO - transformers.tokenization_utils_base -   Model name 'deepset/sentence_bert' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'deepset/sentence_bert' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "08/16/2020 13:02:01 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/deepset/sentence_bert/vocab.txt from cache at /home/kuba/.cache/torch/transformers/205379d98ab8dc0f29c84c5c1c03e3bfef4cd7d58a9d0f6f18636389f3339834.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "08/16/2020 13:02:01 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/deepset/sentence_bert/added_tokens.json from cache at /home/kuba/.cache/torch/transformers/989171ad3bb37d75ff0320403ee6750dfd91417f67b1c2e8d2baa87b4898ca9c.3889713104075cfee9e96090bcdd0dc753733b3db9da20d1dd8b2cd1030536a2\n",
      "08/16/2020 13:02:01 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/deepset/sentence_bert/special_tokens_map.json from cache at /home/kuba/.cache/torch/transformers/07735ccda4d1cf040b9ee6c711c29b65caa6632a10c406c15d0849fcbfbce9a0.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4\n",
      "08/16/2020 13:02:01 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/deepset/sentence_bert/tokenizer_config.json from cache at None\n",
      "08/16/2020 13:02:01 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/deepset/sentence_bert/tokenizer.json from cache at None\n",
      "08/16/2020 13:02:01 - INFO - farm.utils -   device: cuda n_gpu: 1, distributed training: False, automatic mixed precision training: None\n"
     ]
    }
   ],
   "source": [
    "searcher = Searcher(\n",
    "    model_name,\n",
    "    'text',\n",
    "    use_gpu=use_gpu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/16/2020 13:02:02 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "08/16/2020 13:02:02 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 57-0\n",
      "Clear Text: \n",
      " \ttext: Comments\n",
      "Tokenized: \n",
      " \ttokens: ['comments']\n",
      " \toffsets: [0]\n",
      " \tstart_of_word: [True]\n",
      "Features: \n",
      " \tinput_ids: [101, 7928, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tpadding_mask: [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n",
      "08/16/2020 13:02:02 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 140-0\n",
      "Clear Text: \n",
      " \ttext: Rapid progress in machine learning has led to an exponential growth in the number of machine learning papers , with a new paper published … Continue reading on PapersWithCode »\n",
      "Tokenized: \n",
      " \ttokens: ['rapid', 'progress', 'in', 'machine', 'learning', 'has', 'led', 'to', 'an', 'exponential', 'growth', 'in', 'the', 'number', 'of', 'machine', 'learning', 'papers', ',', 'with', 'a', 'new', 'paper', 'published', '…', 'continue', 'reading', 'on', 'papers', '##with', '##code', '»']\n",
      " \toffsets: [0, 6, 15, 18, 26, 35, 39, 43, 46, 49, 61, 68, 71, 75, 82, 85, 93, 102, 109, 111, 116, 118, 122, 128, 138, 140, 149, 157, 160, 166, 170, 175]\n",
      " \tstart_of_word: [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True]\n",
      "Features: \n",
      " \tinput_ids: [101, 5915, 5082, 1999, 3698, 4083, 2038, 2419, 2000, 2019, 27258, 3930, 1999, 1996, 2193, 1997, 3698, 4083, 4981, 1010, 2007, 1037, 2047, 3259, 2405, 1529, 3613, 3752, 2006, 4981, 24415, 16044, 1090, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples: 100%|██████████| 74/74 [00:10<00:00,  7.08 Batches/s]\n"
     ]
    }
   ],
   "source": [
    "searcher.add_texts(feed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_texts = feed_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_strings = pd.read_table('data/topics.txt', header=None).iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deep learning\n",
      "natural language processing\n",
      "computer vision\n",
      "statistics\n",
      "implementation\n",
      "visualization\n",
      "industry\n",
      "software engineering\n",
      "reddit question\n",
      "arxiv\n",
      "cloud computing\n",
      "deployment\n",
      "competitions\n",
      "business\n",
      "business intelligence\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(topic_strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_query_strings = [\n",
    "    'text is about {}'.format(topic)\n",
    "    for topic in topic_strings\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/16/2020 13:02:12 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "08/16/2020 13:02:12 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 0-0\n",
      "Clear Text: \n",
      " \ttext: text is about natural language processing\n",
      "Tokenized: \n",
      " \ttokens: ['text', 'is', 'about', 'natural', 'language', 'processing']\n",
      " \toffsets: [0, 5, 8, 14, 22, 31]\n",
      " \tstart_of_word: [True, True, True, True, True, True]\n",
      "Features: \n",
      " \tinput_ids: [101, 3793, 2003, 2055, 3019, 2653, 6364, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n",
      "08/16/2020 13:02:12 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 0-0\n",
      "Clear Text: \n",
      " \ttext: text is about natural language processing\n",
      "Tokenized: \n",
      " \ttokens: ['text', 'is', 'about', 'natural', 'language', 'processing']\n",
      " \toffsets: [0, 5, 8, 14, 22, 31]\n",
      " \tstart_of_word: [True, True, True, True, True, True]\n",
      "Features: \n",
      " \tinput_ids: [101, 3793, 2003, 2055, 3019, 2653, 6364, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.63 Batches/s]\n"
     ]
    }
   ],
   "source": [
    "raw_results = searcher.retriever.retrieve(\n",
    "    topic_query_strings[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/16/2020 13:02:12 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "08/16/2020 13:02:12 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 9-0\n",
      "Clear Text: \n",
      " \ttext: arxiv\n",
      "Tokenized: \n",
      " \ttokens: ['ar', '##xi', '##v']\n",
      " \toffsets: [0, 2, 4]\n",
      " \tstart_of_word: [True, False, False]\n",
      "Features: \n",
      " \tinput_ids: [101, 12098, 9048, 2615, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n",
      "08/16/2020 13:02:12 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 0-0\n",
      "Clear Text: \n",
      " \ttext: deep learning\n",
      "Tokenized: \n",
      " \ttokens: ['deep', 'learning']\n",
      " \toffsets: [0, 5]\n",
      " \tstart_of_word: [True, True]\n",
      "Features: \n",
      " \tinput_ids: [101, 2784, 4083, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tpadding_mask: [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples: 100%|██████████| 4/4 [00:00<00:00,  7.69 Batches/s]\n",
      "08/16/2020 13:02:13 - INFO - numexpr.utils -   Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "08/16/2020 13:02:13 - INFO - numexpr.utils -   NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "scores_df = searcher.get_topic_score_df( raw_results, topic_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col2 {\n",
       "            background-color:  #1b8f1b;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col3 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col4 {\n",
       "            background-color:  #60b560;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col5 {\n",
       "            background-color:  #b0e2b0;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col6 {\n",
       "            background-color:  #188d18;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col7 {\n",
       "            background-color:  #279527;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col8 {\n",
       "            background-color:  #068306;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col9 {\n",
       "            background-color:  #4caa4c;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col10 {\n",
       "            background-color:  #5eb45e;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col11 {\n",
       "            background-color:  #a0d9a0;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col12 {\n",
       "            background-color:  #abdfab;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col13 {\n",
       "            background-color:  #4dab4d;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col14 {\n",
       "            background-color:  #91d091;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col15 {\n",
       "            background-color:  #e5ffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col16 {\n",
       "            background-color:  #e5ffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col2 {\n",
       "            background-color:  #54ae54;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col3 {\n",
       "            background-color:  #3ba13b;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col4 {\n",
       "            background-color:  #1c8f1c;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col5 {\n",
       "            background-color:  #82c882;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col6 {\n",
       "            background-color:  #67b967;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col7 {\n",
       "            background-color:  #80c780;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col8 {\n",
       "            background-color:  #3fa33f;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col9 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col10 {\n",
       "            background-color:  #52ad52;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col11 {\n",
       "            background-color:  #8bcd8b;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col12 {\n",
       "            background-color:  #58b158;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col13 {\n",
       "            background-color:  #9fd89f;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col14 {\n",
       "            background-color:  #7ac37a;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col15 {\n",
       "            background-color:  #51ad51;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col16 {\n",
       "            background-color:  #3aa03a;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col2 {\n",
       "            background-color:  #329c32;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col3 {\n",
       "            background-color:  #59b159;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col4 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col5 {\n",
       "            background-color:  #7bc47b;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col6 {\n",
       "            background-color:  #91d091;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col7 {\n",
       "            background-color:  #78c278;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col8 {\n",
       "            background-color:  #389f38;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col9 {\n",
       "            background-color:  #1a8e1a;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col10 {\n",
       "            background-color:  #4aa94a;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col11 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col12 {\n",
       "            background-color:  #59b159;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col13 {\n",
       "            background-color:  #a9dea9;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col14 {\n",
       "            background-color:  #8dce8d;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col15 {\n",
       "            background-color:  #65b865;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col16 {\n",
       "            background-color:  #0b860b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col2 {\n",
       "            background-color:  #b1e2b1;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col3 {\n",
       "            background-color:  #5db35d;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col4 {\n",
       "            background-color:  #89cc89;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col5 {\n",
       "            background-color:  #bbe8bb;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col6 {\n",
       "            background-color:  #a1d9a1;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col7 {\n",
       "            background-color:  #e5ffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col8 {\n",
       "            background-color:  #77c277;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col9 {\n",
       "            background-color:  #44a544;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col10 {\n",
       "            background-color:  #e5ffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col11 {\n",
       "            background-color:  #94d294;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col12 {\n",
       "            background-color:  #b2e3b2;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col13 {\n",
       "            background-color:  #ade0ad;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col14 {\n",
       "            background-color:  #e5ffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col15 {\n",
       "            background-color:  #80c780;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col16 {\n",
       "            background-color:  #54ae54;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col2 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col3 {\n",
       "            background-color:  #5ab25a;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col4 {\n",
       "            background-color:  #299729;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col5 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col6 {\n",
       "            background-color:  #349d34;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col7 {\n",
       "            background-color:  #48a848;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col8 {\n",
       "            background-color:  #4daa4d;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col9 {\n",
       "            background-color:  #359d35;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col10 {\n",
       "            background-color:  #4daa4d;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col11 {\n",
       "            background-color:  #caf0ca;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col12 {\n",
       "            background-color:  #93d193;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col13 {\n",
       "            background-color:  #83c983;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col14 {\n",
       "            background-color:  #9dd79d;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col15 {\n",
       "            background-color:  #51ad51;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col16 {\n",
       "            background-color:  #3ba13b;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col2 {\n",
       "            background-color:  #e5ffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col3 {\n",
       "            background-color:  #a1d9a1;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col4 {\n",
       "            background-color:  #e5ffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col5 {\n",
       "            background-color:  #e5ffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col6 {\n",
       "            background-color:  #e5ffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col7 {\n",
       "            background-color:  #defbde;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col8 {\n",
       "            background-color:  #e5ffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col9 {\n",
       "            background-color:  #e5ffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col10 {\n",
       "            background-color:  #2e992e;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col11 {\n",
       "            background-color:  #e5ffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col12 {\n",
       "            background-color:  #e5ffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col13 {\n",
       "            background-color:  #e5ffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col14 {\n",
       "            background-color:  #92d192;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col15 {\n",
       "            background-color:  #d9f8d9;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col16 {\n",
       "            background-color:  #bfeabf;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col2 {\n",
       "            background-color:  #a4dba4;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col3 {\n",
       "            background-color:  #198e19;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col4 {\n",
       "            background-color:  #85ca85;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col5 {\n",
       "            background-color:  #289628;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col6 {\n",
       "            background-color:  #379e37;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col7 {\n",
       "            background-color:  #41a441;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col8 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col9 {\n",
       "            background-color:  #72bf72;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col10 {\n",
       "            background-color:  #43a543;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col11 {\n",
       "            background-color:  #6abb6a;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col12 {\n",
       "            background-color:  #9ad59a;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col13 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col14 {\n",
       "            background-color:  #3aa03a;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col15 {\n",
       "            background-color:  #8dce8d;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col16 {\n",
       "            background-color:  #93d193;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col2 {\n",
       "            background-color:  #289628;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col3 {\n",
       "            background-color:  #138a13;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col4 {\n",
       "            background-color:  #259425;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col5 {\n",
       "            background-color:  #daf9da;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col6 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col7 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col8 {\n",
       "            background-color:  #028102;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col9 {\n",
       "            background-color:  #2f9a2f;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col10 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col11 {\n",
       "            background-color:  #63b763;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col12 {\n",
       "            background-color:  #56af56;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col13 {\n",
       "            background-color:  #3aa03a;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col14 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col15 {\n",
       "            background-color:  #168c16;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col16 {\n",
       "            background-color:  #128a12;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col2 {\n",
       "            background-color:  #5fb55f;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col3 {\n",
       "            background-color:  #0e870e;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col4 {\n",
       "            background-color:  #3aa03a;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col5 {\n",
       "            background-color:  #57b057;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col6 {\n",
       "            background-color:  #1a8e1a;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col7 {\n",
       "            background-color:  #309a30;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col8 {\n",
       "            background-color:  #2e992e;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col9 {\n",
       "            background-color:  #319b31;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col10 {\n",
       "            background-color:  #6ebd6e;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col11 {\n",
       "            background-color:  #bae7ba;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col12 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col13 {\n",
       "            background-color:  #5db35d;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col14 {\n",
       "            background-color:  #4eab4e;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col15 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col16 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col2 {\n",
       "            background-color:  #a7dda7;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col3 {\n",
       "            background-color:  #e5ffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col4 {\n",
       "            background-color:  #4daa4d;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col5 {\n",
       "            background-color:  #a1d9a1;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col6 {\n",
       "            background-color:  #b3e3b3;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col7 {\n",
       "            background-color:  #6abb6a;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col8 {\n",
       "            background-color:  #75c175;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col9 {\n",
       "            background-color:  #90d090;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col10 {\n",
       "            background-color:  #3ca13c;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col11 {\n",
       "            background-color:  #6abb6a;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col12 {\n",
       "            background-color:  #7ec67e;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col13 {\n",
       "            background-color:  #a0d9a0;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col14 {\n",
       "            background-color:  #79c379;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col15 {\n",
       "            background-color:  #cff3cf;\n",
       "            color:  #000000;\n",
       "        }    #T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col16 {\n",
       "            background-color:  #b8e6b8;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >title</th>        <th class=\"col_heading level0 col1\" >text</th>        <th class=\"col_heading level0 col2\" >deep learning</th>        <th class=\"col_heading level0 col3\" >natural language processing</th>        <th class=\"col_heading level0 col4\" >computer vision</th>        <th class=\"col_heading level0 col5\" >statistics</th>        <th class=\"col_heading level0 col6\" >implementation</th>        <th class=\"col_heading level0 col7\" >visualization</th>        <th class=\"col_heading level0 col8\" >industry</th>        <th class=\"col_heading level0 col9\" >software engineering</th>        <th class=\"col_heading level0 col10\" >reddit question</th>        <th class=\"col_heading level0 col11\" >arxiv</th>        <th class=\"col_heading level0 col12\" >cloud computing</th>        <th class=\"col_heading level0 col13\" >deployment</th>        <th class=\"col_heading level0 col14\" >competitions</th>        <th class=\"col_heading level0 col15\" >business</th>        <th class=\"col_heading level0 col16\" >business intelligence</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col0\" class=\"data row0 col0\" >Evaluating the Impact of Knowledge Graph Context on Entity Disambiguation Models</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col1\" class=\"data row0 col1\" >Pretrained Transformer models have emerged as state-of-the-art approaches that learn contextual information from the text to improve the performance of several NLP tasks. Code: https://github.com/mulangonando/Impact-of-KG-Context-on-ED</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col2\" class=\"data row0 col2\" >0.613387</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col3\" class=\"data row0 col3\" >0.597722</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col4\" class=\"data row0 col4\" >0.531973</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col5\" class=\"data row0 col5\" >0.501481</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col6\" class=\"data row0 col6\" >0.593792</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col7\" class=\"data row0 col7\" >0.559076</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col8\" class=\"data row0 col8\" >0.545501</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col9\" class=\"data row0 col9\" >0.592912</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col10\" class=\"data row0 col10\" >0.543777</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col11\" class=\"data row0 col11\" >0.490492</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col12\" class=\"data row0 col12\" >0.511187</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col13\" class=\"data row0 col13\" >0.537554</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col14\" class=\"data row0 col14\" >0.530916</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col15\" class=\"data row0 col15\" >0.494104</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row0_col16\" class=\"data row0 col16\" >0.496908</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col0\" class=\"data row1 col0\" >Feature Engineering with NLP</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col1\" class=\"data row1 col1\" >Converting tokens of text into features and applying machine learning and deep learning model on it.Continue reading on Towards AI — Multidisciplinary Science Journal »</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col2\" class=\"data row1 col2\" >0.597072</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col3\" class=\"data row1 col3\" >0.590448</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col4\" class=\"data row1 col4\" >0.549067</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col5\" class=\"data row1 col5\" >0.511888</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col6\" class=\"data row1 col6\" >0.567869</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col7\" class=\"data row1 col7\" >0.536750</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col8\" class=\"data row1 col8\" >0.531344</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col9\" class=\"data row1 col9\" >0.617110</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col10\" class=\"data row1 col10\" >0.547273</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col11\" class=\"data row1 col11\" >0.493482</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col12\" class=\"data row1 col12\" >0.531765</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col13\" class=\"data row1 col13\" >0.509824</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col14\" class=\"data row1 col14\" >0.536120</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col15\" class=\"data row1 col15\" >0.519174</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row1_col16\" class=\"data row1 col16\" >0.530965</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col0\" class=\"data row2 col0\" >Introduction to Natural Language Processing</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col1\" class=\"data row2 col1\" >NLP is a great tool to analyze text data and perform an amazing task when combined with machine learning and deep learning. So, let’s look…Continue reading on Towards AI — Multidisciplinary Science Journal »</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col2\" class=\"data row2 col2\" >0.606703</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col3\" class=\"data row2 col3\" >0.586747</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col4\" class=\"data row2 col4\" >0.556306</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col5\" class=\"data row2 col5\" >0.513555</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col6\" class=\"data row2 col6\" >0.553962</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col7\" class=\"data row2 col7\" >0.538722</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col8\" class=\"data row2 col8\" >0.533227</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col9\" class=\"data row2 col9\" >0.608819</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col10\" class=\"data row2 col10\" >0.549520</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col11\" class=\"data row2 col11\" >0.514010</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col12\" class=\"data row2 col12\" >0.531522</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col13\" class=\"data row2 col13\" >0.506409</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col14\" class=\"data row2 col14\" >0.531768</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col15\" class=\"data row2 col15\" >0.515964</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row2_col16\" class=\"data row2 col16\" >0.540105</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col0\" class=\"data row3 col0\" >A single legal text representation at Doctrine: the legal camemBERT</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col1\" class=\"data row3 col1\" >As a legal platform, Doctrine aggregates a lot of legal data with the intent of making them accessible, understandable and usable. The Machine Learning Engineers’ day-to-day material is mostly text: court decisions, legislation, legal commentaries, user queries, etc. All of our content is natural language, which we process in a number of ways: bag-of-words, embeddings or with language models.In an ideal world though, our product would be built on top of scalable, flexible and reusable modules, ones that would be generic enough to accommodate a wide variety of legal contents and feed the whole spectrum of our product features. It is exactly with that vision in mind that we started working on a unified language model a few months ago, whose associated challenges, findings and results we’ll do our best to summarize in this article.I. One language model to rule them allDepending on the project, we were representing our legal contents with:different techniques:TF-IDF vectorsBM25 (e.g., with ElasticSearch)A variant of Word2Vec, called Wang2Vec, embeddings fine-tuned on legal data — note that even if those embeddings work pretty well for a lot of tasks, they are not the state-of-the-art anymore. There’s not enough modeling power in simple word embeddings and we definitely see their limits now on some tasks.2. different data:vocabulary of the content itself,vocabulary of the linked contents from our legal graphvocabulary from some metadata provided by the courts…Yet eventually, we want to be able to represent all of our legal content using a unified framework for any text-understanding based feature, because of:Reusability: all teams can rely on this unique language model for their projects.2. Scalability:a modeling power sufficient to be applied to any new legal content (e.g., legal documents from the lower house and the upper house),robust enough to unlock use cases we’re not yet considering, like legal bots, legal trend detection, argument mining, etc,generic enough to be applied to a new language (with a retraining on the new language of course).3. Agnostic usage: one of the problems with our current representations is that the text follows some guidelines in the way they phrase statements, and a textual similarity is thus strongly biased towards documents that have the same overall phrasing (of the same court for example), despite the fact they’re not invoking the same laws about the same thing. For example, it is now difficult for us to match decisions from the High Court/Court of Appeal to those from the Supreme Court simply because of their different writing styles (the former tends to focus primarily and precisely on the facts, while the latter favors usually only relies on the legal matter, which has an adverse effect on our current representations).When we initially started thinking about this, there were some properties that we thought our language model should ideally cover:Taking advantage of the semantic proximity:In French:préjudice corporel should be equivalent to dommage corporelIn English: death should be equivalent to loss of life2. Being able to represent our content on different granularities:Token-level for Named Entity Recognition: anonymization, entity detection, …Paragraph-level: structure detection, argument similarities, …Document-level: legal domain classification, document recommendation, …It’s with all those things in mind that we started to work on a unique, all-encompassing language model serving all our use cases and features.II. Our legal language modelThe first step of this project was to design the architecture and implementation of our language model. This step was crucial since it would serve as the foundation to all of our future work and help us move towards our initial vision. We first thought about our technical constraints:use an existing and robust implementation, in order to take advantage of the support and the community,use a state-of-the-art technique to achieve very good performances,ideally use a PyTorch implementation, because our previous Deep Learning algorithms were made with PyTorch. Moreover, PyTorch (along with a few others) remains the dominant deep learning library at the time of writing this article,if possible, find an implementation with a French pre-trained model before fine-tuning, because transfer learning has shown its efficiency in NLP.It should also be noted that compared to other use-cases, especially in academic research, the framework should be efficient at representing very long texts. Here is an interesting blog post about different document embeddings techniques. We’ll come to that later.Under these constraints, the Hugging Face Transformers library appeared to be a very good choice:they offer all the recent state-of-the-art architectures (BERT, RoBERTa, ELMo, XLNet, …) complete with their associated PyTorch and TensorFlow implementations,some of them have a French pre-trained model,their implementation has quickly become an international reference, to the point where the famous NLP framework Spacy provides a Transformer implementation based on the Hugging Face one.Among the models providing a French pre-trained model, we had the choice between:BERT-Base, multilingualDistilmBERT, multilingualcamemBERT, French RoBERTa modelWe decided to go for camemBERT, since it already provided good results for the French language on several tasks according to this paper. Of course, multilingual models will probably be very useful for internationalization later, but we initially wanted to check that a transformer model could be relevant. Moreover, camemBERT has fewer parameters than multilingual models, which makes it a little easier to use.Note that camemBERT is case-sensitive, which will be useful for Named Entity Recognition and especially for anonymization.The legal CamemBERTNow that we had settled on the underlying technology, we decided to check how well it would perform on actual, real-life legal data.Knowing that camemBERT was initially trained on the French subcorpus of OSCAR, which features gigabytes of data crawled from the web, we knew that it would fare well at general French language tasks, but we suspected that the task of speaking the more specific French legalese would prove to be a tougher nut to crack, which our initial tests confirmed.For example, when asked to predict the next word of the sentence Par ces ... , camemBERT suggested the word mots, which is not exactly legal-oriented. We would expect something like moyens or motifs.It was obvious at this point that the trove of millions of legal documents we have at our disposal at Doctrine would prove to be great material for the subsequent fine-tuning needed to harness the full power of our model. At this point, we were confident that the model could be trained, however, we needed it to be potentially used universally across features. Yet, one issue remained: how to handle long texts, a strong prerequisite for legal documents, but something that doesn’t pair naturally with transformers’ inherent limitations.BERT models, for example, have a hard limit of 512 to 514 tokens (as enforced by the max_position_embeddings parameter), which would surely be a challenge when dealing with court decisions: texts that can be infamously verbose, with an average token count hovering around 2000 (and some even more extreme cases like this decision).To circumvent this issue, we envisioned two different approaches:Embedding each paragraphHaving sliding windows, as explained hereTo avoid ending up with redundancy in the embeddings, we decided to go with paragraph embeddings first, with exceedingly long paragraphs getting snipped past the limit during training. What was left for us to determine at that point was an aggregation strategy over the different paragraphs, so that we could harvest the final document embeddings, something that we would come back to later.We then proceeded with the implementation, which was done by splitting our legal documents on paragraphs and fine-tuning camemBERT on the masked language model task (using dedicated AWS GPU instances). It converged after a few days and we tested its relevance by using a few qualitative checks:Comparison between the standard pre-trained French camemBERT model and our legal camemBERT on a masked LM taskWe assessed the differences in prediction for semantically similar sentences, which seemed to be consistent. The qualitative check seemed to provide very good results. It was now time to validate the language model on a real task.III. Our first legal camemBERT use-case: classification of legal domainWe wanted to try our legal camemBERT on a simple task for a first validation: text classification of legal domains on court decisions.This is indeed a simple and well delimited task, and easy to compare to other basic models. Moreover, this classification has a huge product impact, on the search filters, recommender systems and analytics.We have two hierarchies on the legal domains at Doctrine:the main legal domain:Droit civil,Droit commercial,Droit social,Droit public,…2. the subdomain: for example in Droit civil, there areDivorce et séparation de corpsDroit locatifDroit des successionsDroit de la responsabilité…Today, we support 9 different domains and 40 different subdomains, where some are more complex than others to determine. These categories have a hierarchical structure, but we addressed the problem by reducing it to a 40-class classification problem.The HuggingFace repository suggests a classification head module integrated with CamemBERT. However, as discussed earlier, the main problem is that court decisions can be very verbose (have a look at this very long decision for example), and BERT does not work well on long texts. A very good review of document embeddings showed that there are no clear embedding technique that works better than others for very long documents. It really depends on your objective.Working at a paragraph level seemed more relevant, all the more so as the language model has been trained at a paragraph scale. BERT will then provide an embedding for each paragraph. We then had to think about a way to aggregate the paragraphs in order to get a decision embedding.ModelingParagraph embeddings methodIt is known that BERT architectures provide not only word-level contextual embeddings but also the special CLS-token whose output embedding is used for classification tasks. However it turns out to be a poor embedding of the input sequence of other tasks if not fine-tuned on the specific task:The paper Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks from Reimers et al, 2019, shows that BERT out-of-the-box maps sentences to a vector space that is rather unsuitable to be used with common similarity measures like cosine-similarity.According to BERT creator Jacob Devlin: “I’m not sure what these vectors are, since BERT does not generate meaningful sentence vectors. It seems that this is is doing average pooling over the word tokens to get a sentence vector, but we never suggested that this will generate meaningful sentence representations.” sourceStill, the most classic ways to embed a document (in our case, a paragraph) with BERT are:to use the [CLS]-tokento use an aggregation of the last X hidden states of the word embeddings ( we usually saw X=4)What is interesting in our case is that one paragraph does not represent the whole court decision. We had to plug something on top of it. We decided to go with the [CLS]-token as paragraph embeddings for a first shot, because our task is a classification task.2. Document embedding with an aggregation over paragraphsGiven embeddings for all our paragraphs, we then had to think of a way to get document embeddings.Here again, different approaches can be considered, since this is another sequence-to-one vector modeling:A simple average of all paragraph embeddings (the [CLS]-token of each BERT-output paragraphs),A weighted average of the paragraph embeddings, with weights built with a self-attention mechanism explained in the paper A Structured Self-attentive Sentence Embedding,A bi-LSTM to exploit the sequential information contained in the paragraphs,A Convolutional Neural Network,Another BERT that would learn the language at the paragraph scale,…Given that our task is a mere classification problem, the solution with a self-attention mechanism seemed to be pretty relevant for our case because:It’s a bit smarter than a simple average-pooling, and it will automatically get rid of the useless paragraphs that contain no information for the legal domain. Indeed, the final paragraphs of French decisions are often related to the operative part of the judgment, and about who pays the costs. This is usually not relevant to our current problem.It also provides some precious insights on how to best interpret the model. We can indeed have access to the attention weights and check on which paragraphs the model focused on the most for its prediction.With all that mind, here’s the final architecture for the classification task:Final architecture of our legal document classification on documents, using the legal camemBERTWe first tried to train the whole pipeline, including the fine-tuning of the legal camemBERT on this task, but we got memory errors. We quickly froze the BERT model and trained only the rest of the pipeline (attention layer + classification layer). It provided good results so we didn’t go with further experiments on an end-to-end training. This is something that we made a note of though, since unsupervised BERT outputs are known to be poor if not fine-tuned, as discussed earlier in this article.ResultsThe goal here was not only to improve our legal domains classification, but also to show that we could achieve at least the same results as a simple TF-IDF model.Dataset creationDeep learning in general often requires a consequent training set size. That’s why we used a semi-automatically labelled training dataset, labelled:by humans, using Prodi.gywith business rules, using the associated court as a reference. If a decision is linked to another one from Labor court, it’s very likely that the decision is about Droit du travail(labor laws).with the most reliable predictions of our former algorithm, based on TF-IDF for the domain, and a legal taxonomy for the subdomain.Comparison between models and discussionWe achieved the same performance with our legal camemBERT and with a simple TF-IDF, which is actually good news! We indeed didn’t spend a lot of time on the modeling part of camemBERT, and this classification task is in the end a rather simple NLP task.Moreover and perhaps just as interestingly, we noticed after a qualitative analysis of model’s prediction errors that the errors of the simple model were more often out of context. It means that when the TF-IDF gets it wrong, it’s really way off the mark. For example, this decision is predicted as Droit du transport with a probability of 0.96, instead of Droit des assurances because the decision is about a vehicle insurance claim and contains a lot of vocabulary related to transportation, and not that much about insurance.On the other hand, the legal camemBERT can of course be wrong, but it never steers too much out of context and will mostly predict subdomains that are very close, like Droit immobilier et de la construction and Droit de la copropriété et de la propriété immobilière, when we look at the confusion matrix.Moreover, CamemBERT managed to predict some subdomains that were not obvious at all, even for humans. For example, this decision has been predicted as Divorce et séparations de corpswithout any explicit mention of the word divorce in the decision! The subdomain here is very implicit and implied by a mention to a father that has to pay alimony to the mother of his child.Let’s now have a look at the attention weights of our modeling. Here are some examples below:Paragraph with the highest attention score (0.34) for the prediction of https://www.doctrine.fr/d/CA/Reims/2008/SK60FC7292250FC0B001E6 as Divorce et Séparation de corpsParagraph with the highest attention score (0.26) for the prediction of https://www.doctrine.fr/d/CA/Rouen/2016/1F43DFAE32435B18DC90 as Droit des étrangers et de la nationalitéThese attention scores totally make sense, and confirmed the approach.We also confirmed that paragraphs related to generic procedures had a very low attention weight, like this one:Paragraph with a very low attention weight of 0.01 for the prediction of https://www.doctrine.fr/d/CA/Rouen/2016/1F43DFAE32435B18DC90 as Droit des étrangers et de la nationalitéFinally, when we had a look at the errors of the models (both models), we quickly noticed that some classes were very well predicted and some others were not. Our intuition about the observed discrepancy boils down to the fact that language models are only ever as good as their training dataset. In our case, the issue seems to stem from volume and errors in the training set. This is definitely the next priority for this task to focus on, before trying to play with the different architectures. Indeed, the current one seems to work pretty well on subdomains when the training dataset is satisfactory.ConclusionWe built a legal language model with a state-of-the-art technique, that proved to be very efficient at capturing highly relevant information on a simple classification task. This is a huge step for Doctrine, as we have a lot of very complex tasks in Natural Language Processing to tackle! The granularity of this new language model, which can seamlessly provide token, paragraph and document embeddings will be key for us to find new applications for the technique on a wide array of complex Natural Language Processing tasks at Doctrine.In fact, the legal camemBERT has already found a second problem to tackle with the issue of semantic similarity between users and legal content in the context of a recommendation system and seems to already have yielded promising results, which we’ll be sharing in an upcoming blog post very soon. Stay tuned!A single legal text representation at Doctrine: the legal camemBERT was originally published in Inside Doctrine on Medium, where people are continuing the conversation by highlighting and responding to this story.</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col2\" class=\"data row3 col2\" >0.570231</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col3\" class=\"data row3 col3\" >0.586314</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col4\" class=\"data row3 col4\" >0.521751</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col5\" class=\"data row3 col5\" >0.499045</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col6\" class=\"data row3 col6\" >0.548911</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col7\" class=\"data row3 col7\" >0.511261</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col8\" class=\"data row3 col8\" >0.517473</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col9\" class=\"data row3 col9\" >0.595577</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col10\" class=\"data row3 col10\" >0.505991</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col11\" class=\"data row3 col11\" >0.492187</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col12\" class=\"data row3 col12\" >0.509414</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col13\" class=\"data row3 col13\" >0.505175</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col14\" class=\"data row3 col14\" >0.512034</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col15\" class=\"data row3 col15\" >0.511341</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row3_col16\" class=\"data row3 col16\" >0.525712</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col0\" class=\"data row4 col0\" >A Large-Scale Chinese Short-Text Conversation Dataset</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col1\" class=\"data row4 col1\" >The cleaned dataset and the pre-training models will facilitate the research of short-text conversation modeling. Code: https://github.com/thu-coai/CDial-GPT</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col2\" class=\"data row4 col2\" >0.621184</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col3\" class=\"data row4 col3\" >0.586691</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col4\" class=\"data row4 col4\" >0.545824</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col5\" class=\"data row4 col5\" >0.541583</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col6\" class=\"data row4 col6\" >0.584535</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col7\" class=\"data row4 col7\" >0.550647</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col8\" class=\"data row4 col8\" >0.527896</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col9\" class=\"data row4 col9\" >0.600209</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col10\" class=\"data row4 col10\" >0.548811</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col11\" class=\"data row4 col11\" >0.484411</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col12\" class=\"data row4 col12\" >0.517256</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col13\" class=\"data row4 col13\" >0.519267</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col14\" class=\"data row4 col14\" >0.528229</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col15\" class=\"data row4 col15\" >0.519199</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row4_col16\" class=\"data row4 col16\" >0.530539</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col0\" class=\"data row5 col0\" >[Q] Data scientist here, working on gathering a corpus of academic papers focusing on \"Cognitive Linguistics\". Need your help!</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col1\" class=\"data row5 col1\" >Hello. I want to collect as many as papers as I can that will fall into this category. The main problem is that the \"tagging\" is not consistent for linguistic papers. Hence I'm looking for an exhausitve list of tags which are directly related to this field, in order to make better queries and find more relevant data.  Thanks!    submitted by    /u/quit_daedalus   [link] [comments]</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col2\" class=\"data row5 col2\" >0.555300</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col3\" class=\"data row5 col3\" >0.578011</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col4\" class=\"data row5 col4\" >0.498356</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col5\" class=\"data row5 col5\" >0.489413</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col6\" class=\"data row5 col6\" >0.526189</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col7\" class=\"data row5 col7\" >0.513210</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col8\" class=\"data row5 col8\" >0.489906</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col9\" class=\"data row5 col9\" >0.544217</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col10\" class=\"data row5 col10\" >0.557324</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col11\" class=\"data row5 col11\" >0.480271</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col12\" class=\"data row5 col12\" >0.496461</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col13\" class=\"data row5 col13\" >0.485666</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col14\" class=\"data row5 col14\" >0.530694</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col15\" class=\"data row5 col15\" >0.496379</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row5_col16\" class=\"data row5 col16\" >0.504614</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col0\" class=\"data row6 col0\" >KR-BERT: A Small-Scale Korean-Specific Language Model</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col1\" class=\"data row6 col1\" >Since the appearance of BERT, recent works including XLNet and RoBERTa utilize sentence embedding models pre-trained by large corpora and a large number of parameters. Code: https://github.com/snunlp/KR-BERT</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col2\" class=\"data row6 col2\" >0.574174</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col3\" class=\"data row6 col3\" >0.594593</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col4\" class=\"data row6 col4\" >0.522638</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col5\" class=\"data row6 col5\" >0.532562</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col6\" class=\"data row6 col6\" >0.583562</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col7\" class=\"data row6 col7\" >0.552562</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col8\" class=\"data row6 col8\" >0.547111</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col9\" class=\"data row6 col9\" >0.580898</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col10\" class=\"data row6 col10\" >0.551625</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col11\" class=\"data row6 col11\" >0.498453</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col12\" class=\"data row6 col12\" >0.515522</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col13\" class=\"data row6 col13\" >0.564181</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col14\" class=\"data row6 col14\" >0.550184</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col15\" class=\"data row6 col15\" >0.508991</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row6_col16\" class=\"data row6 col16\" >0.513304</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col0\" class=\"data row7 col0\" >Dialogue State Induction Using Neural Latent Variable Models</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col1\" class=\"data row7 col1\" >Dialogue state modules are a useful component in a task-oriented dialogue system. Code: https://github.com/taolusi/dialogue-state-induction</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col2\" class=\"data row7 col2\" >0.609547</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col3\" class=\"data row7 col3\" >0.595336</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col4\" class=\"data row7 col4\" >0.546996</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col5\" class=\"data row7 col5\" >0.492073</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col6\" class=\"data row7 col6\" >0.601822</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col7\" class=\"data row7 col7\" >0.568787</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col8\" class=\"data row7 col8\" >0.546473</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col9\" class=\"data row7 col9\" >0.602195</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col10\" class=\"data row7 col10\" >0.570310</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col11\" class=\"data row7 col11\" >0.499499</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col12\" class=\"data row7 col12\" >0.532563</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col13\" class=\"data row7 col13\" >0.543948</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col14\" class=\"data row7 col14\" >0.563158</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col15\" class=\"data row7 col15\" >0.529331</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row7_col16\" class=\"data row7 col16\" >0.538693</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col0\" class=\"data row8 col0\" >Inter-Image Communication for Weakly Supervised Localization</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col1\" class=\"data row8 col1\" >We learn a feature center for each category and realize the global feature consistency by forcing the object features to approach class-specific centers. Code: https://github.com/xiaomengyc/I2C</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col2\" class=\"data row8 col2\" >0.593860</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col3\" class=\"data row8 col3\" >0.596002</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col4\" class=\"data row8 col4\" >0.541500</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col5\" class=\"data row8 col5\" >0.521783</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col6\" class=\"data row8 col6\" >0.593086</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col7\" class=\"data row8 col7\" >0.556799</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col8\" class=\"data row8 col8\" >0.535707</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col9\" class=\"data row8 col9\" >0.601382</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col10\" class=\"data row8 col10\" >0.539489</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col11\" class=\"data row8 col11\" >0.486664</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col12\" class=\"data row8 col12\" >0.553956</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col13\" class=\"data row8 col13\" >0.532525</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col14\" class=\"data row8 col14\" >0.545695</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col15\" class=\"data row8 col15\" >0.532982</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row8_col16\" class=\"data row8 col16\" >0.542407</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col0\" class=\"data row9 col0\" >TextRay: Contour-based Geometric Modeling for Arbitrary-shaped Scene Text Detection</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col1\" class=\"data row9 col1\" >Arbitrary-shaped text detection is a challenging task due to the complex geometric layouts of texts such as large aspect ratios, various scales, random rotations and curve shapes. Code: https://github.com/LianaWang/TextRay</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col2\" class=\"data row9 col2\" >0.573135</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col3\" class=\"data row9 col3\" >0.569583</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col4\" class=\"data row9 col4\" >0.536931</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col5\" class=\"data row9 col5\" >0.505102</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col6\" class=\"data row9 col6\" >0.543021</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col7\" class=\"data row9 col7\" >0.542183</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col8\" class=\"data row9 col8\" >0.517943</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col9\" class=\"data row9 col9\" >0.571432</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col10\" class=\"data row9 col10\" >0.553461</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col11\" class=\"data row9 col11\" >0.498335</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col12\" class=\"data row9 col12\" >0.522298</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col13\" class=\"data row9 col13\" >0.509426</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col14\" class=\"data row9 col14\" >0.536340</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col15\" class=\"data row9 col15\" >0.498024</td>\n",
       "                        <td id=\"T_f05b6d52_dfaf_11ea_ac36_f4d108645659row9_col16\" class=\"data row9 col16\" >0.506026</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fccb6eb2c50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.style.background_gradient(cmap=cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pretrained Transformer models have emerged as state-of-the-art approaches that learn contextual information from the text to improve the performance of several NLP tasks. Code: https://github.com/mulangonando/Impact-of-KG-Context-on-ED',\n",
       " 'Converting tokens of text into features and applying machine learning and deep learning model on it.Continue reading on Towards AI\\u200a—\\u200aMultidisciplinary Science Journal »',\n",
       " 'NLP is a great tool to analyze text data and perform an amazing task when combined with machine learning and deep learning. So, let’s look…Continue reading on Towards AI\\u200a—\\u200aMultidisciplinary Science Journal »',\n",
       " 'As a legal platform, Doctrine aggregates a lot of legal data with the intent of making them accessible, understandable and usable. The Machine Learning Engineers’ day-to-day material is mostly text: court decisions, legislation, legal commentaries, user queries, etc. All of our content is natural language, which we process in a number of ways: bag-of-words, embeddings or with language\\xa0models.In an ideal world though, our product would be built on top of scalable, flexible and reusable modules, ones that would be generic enough to accommodate a wide variety of legal contents and feed the whole spectrum of our product features. It is exactly with that vision in mind that we started working on a unified language model a few months ago, whose associated challenges, findings and results we’ll do our best to summarize in this\\xa0article.I. One language model to rule them\\xa0allDepending on the project, we were representing our legal contents\\xa0with:different techniques:TF-IDF vectorsBM25 (e.g., with ElasticSearch)A variant of Word2Vec, called Wang2Vec, embeddings fine-tuned on legal data\\u200a—\\u200anote that even if those embeddings work pretty well for a lot of tasks, they are not the state-of-the-art anymore. There’s not enough modeling power in simple word embeddings and we definitely see their limits now on some\\xa0tasks.2. different data:vocabulary of the content\\xa0itself,vocabulary of the linked contents from our legal\\xa0graphvocabulary from some metadata provided by the\\xa0courts…Yet eventually, we want to be able to represent all of our legal content using a unified framework for any text-understanding based feature, because\\xa0of:Reusability: all teams can rely on this unique language model for their projects.2. Scalability:a modeling power sufficient to be applied to any new legal content (e.g., legal documents from the lower house and the upper\\xa0house),robust enough to unlock use cases we’re not yet considering, like legal bots, legal trend detection, argument mining,\\xa0etc,generic enough to be applied to a new language (with a retraining on the new language of\\xa0course).3. Agnostic usage: one of the problems with our current representations is that the text follows some guidelines in the way they phrase statements, and a textual similarity is thus strongly biased towards documents that have the same overall phrasing (of the same court for example), despite the fact they’re not invoking the same laws about the same thing. For example, it is now difficult for us to match decisions from the High Court/Court of Appeal to those from the Supreme Court simply because of their different writing styles (the former tends to focus primarily and precisely on the facts, while the latter favors usually only relies on the legal matter, which has an adverse effect on our current representations).When we initially started thinking about this, there were some properties that we thought our language model should ideally\\xa0cover:Taking advantage of the semantic proximity:In French:préjudice corporel should be equivalent to dommage\\xa0corporelIn English: death should be equivalent to loss of\\xa0life2. Being able to represent our content on different granularities:Token-level for Named Entity Recognition: anonymization, entity detection,\\xa0…Paragraph-level: structure detection, argument similarities,\\xa0…Document-level: legal domain classification, document recommendation,\\xa0…It’s with all those things in mind that we started to work on a unique, all-encompassing language model serving all our use cases and features.II. Our legal language\\xa0modelThe first step of this project was to design the architecture and implementation of our language model. This step was crucial since it would serve as the foundation to all of our future work and help us move towards our initial vision. We first thought about our technical constraints:use an existing and robust implementation, in order to take advantage of the support and the community,use a state-of-the-art technique to achieve very good performances,ideally use a PyTorch implementation, because our previous Deep Learning algorithms were made with PyTorch. Moreover, PyTorch (along with a few others) remains the dominant deep learning library at the time of writing this\\xa0article,if possible, find an implementation with a French pre-trained model before fine-tuning, because transfer learning has shown its efficiency in\\xa0NLP.It should also be noted that compared to other use-cases, especially in academic research, the framework should be efficient at representing very long texts. Here is an interesting blog post about different document embeddings techniques. We’ll come to that\\xa0later.Under these constraints, the Hugging Face Transformers library appeared to be a very good\\xa0choice:they offer all the recent state-of-the-art architectures (BERT, RoBERTa, ELMo, XLNet,\\xa0…) complete with their associated PyTorch and TensorFlow implementations,some of them have a French pre-trained model,their implementation has quickly become an international reference, to the point where the famous NLP framework Spacy provides a Transformer implementation based on the Hugging Face\\xa0one.Among the models providing a French pre-trained model, we had the choice\\xa0between:BERT-Base, multilingualDistilmBERT, multilingualcamemBERT, French RoBERTa\\xa0modelWe decided to go for camemBERT, since it already provided good results for the French language on several tasks according to this paper. Of course, multilingual models will probably be very useful for internationalization later, but we initially wanted to check that a transformer model could be relevant. Moreover, camemBERT has fewer parameters than multilingual models, which makes it a little easier to\\xa0use.Note that camemBERT is case-sensitive, which will be useful for Named Entity Recognition and especially for anonymization.The legal CamemBERTNow that we had settled on the underlying technology, we decided to check how well it would perform on actual, real-life legal\\xa0data.Knowing that camemBERT was initially trained on the French subcorpus of OSCAR, which features gigabytes of data crawled from the web, we knew that it would fare well at general French language tasks, but we suspected that the task of speaking the more specific French legalese would prove to be a tougher nut to crack, which our initial tests confirmed.For example, when asked to predict the next word of the sentence Par ces\\xa0...\\xa0, camemBERT suggested the word mots, which is not exactly legal-oriented. We would expect something like moyens or\\xa0motifs.It was obvious at this point that the trove of millions of legal documents we have at our disposal at Doctrine would prove to be great material for the subsequent fine-tuning needed to harness the full power of our model. At this point, we were confident that the model could be trained, however, we needed it to be potentially used universally across features. Yet, one issue remained: how to handle long texts, a strong prerequisite for legal documents, but something that doesn’t pair naturally with transformers’ inherent limitations.BERT models, for example, have a hard limit of 512 to 514 tokens (as enforced by the max_position_embeddings parameter), which would surely be a challenge when dealing with court decisions: texts that can be infamously verbose, with an average token count hovering around 2000 (and some even more extreme cases like this decision).To circumvent this issue, we envisioned two different approaches:Embedding each paragraphHaving sliding windows, as explained hereTo avoid ending up with redundancy in the embeddings, we decided to go with paragraph embeddings first, with exceedingly long paragraphs getting snipped past the limit during training. What was left for us to determine at that point was an aggregation strategy over the different paragraphs, so that we could harvest the final document embeddings, something that we would come back to\\xa0later.We then proceeded with the implementation, which was done by splitting our legal documents on paragraphs and fine-tuning camemBERT on the masked language model task (using dedicated AWS GPU instances). It converged after a few days and we tested its relevance by using a few qualitative checks:Comparison between the standard pre-trained French camemBERT model and our legal camemBERT on a masked LM\\xa0taskWe assessed the differences in prediction for semantically similar sentences, which seemed to be consistent. The qualitative check seemed to provide very good results. It was now time to validate the language model on a real\\xa0task.III. Our first legal camemBERT use-case: classification of legal\\xa0domainWe wanted to try our legal camemBERT on a simple task for a first validation: text classification of legal domains on court decisions.This is indeed a simple and well delimited task, and easy to compare to other basic models. Moreover, this classification has a huge product impact, on the search filters, recommender systems and analytics.We have two hierarchies on the legal domains at Doctrine:the main legal\\xa0domain:Droit civil,Droit commercial,Droit social,Droit public,…2. the subdomain: for example in Droit civil, there\\xa0areDivorce et séparation de\\xa0corpsDroit locatifDroit des successionsDroit de la responsabilité…Today, we support 9 different domains and 40 different subdomains, where some are more complex than others to determine. These categories have a hierarchical structure, but we addressed the problem by reducing it to a 40-class classification problem.The HuggingFace repository suggests a classification head module integrated with CamemBERT. However, as discussed earlier, the main problem is that court decisions can be very verbose (have a look at this very long decision for example), and BERT does not work well on long texts. A very good review of document embeddings showed that there are no clear embedding technique that works better than others for very long documents. It really depends on your objective.Working at a paragraph level seemed more relevant, all the more so as the language model has been trained at a paragraph scale. BERT will then provide an embedding for each paragraph. We then had to think about a way to aggregate the paragraphs in order to get a decision embedding.ModelingParagraph embeddings methodIt is known that BERT architectures provide not only word-level contextual embeddings but also the special CLS-token whose output embedding is used for classification tasks. However it turns out to be a poor embedding of the input sequence of other tasks if not fine-tuned on the specific\\xa0task:The paper Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks from Reimers et al, 2019, shows that BERT out-of-the-box maps sentences to a vector space that is rather unsuitable to be used with common similarity measures like cosine-similarity.According to BERT creator Jacob Devlin: “I’m not sure what these vectors are, since BERT does not generate meaningful sentence vectors. It seems that this is is doing average pooling over the word tokens to get a sentence vector, but we never suggested that this will generate meaningful sentence representations.” sourceStill, the most classic ways to embed a document (in our case, a paragraph) with BERT\\xa0are:to use the [CLS]-tokento use an aggregation of the last X hidden states of the word embeddings ( we usually saw\\xa0X=4)What is interesting in our case is that one paragraph does not represent the whole court decision. We had to plug something on top of it. We decided to go with the [CLS]-token as paragraph embeddings for a first shot, because our task is a classification task.2. Document embedding with an aggregation over paragraphsGiven embeddings for all our paragraphs, we then had to think of a way to get document embeddings.Here again, different approaches can be considered, since this is another sequence-to-one vector modeling:A simple average of all paragraph embeddings (the [CLS]-token of each BERT-output paragraphs),A weighted average of the paragraph embeddings, with weights built with a self-attention mechanism explained in the paper A Structured Self-attentive Sentence Embedding,A bi-LSTM to exploit the sequential information contained in the paragraphs,A Convolutional Neural\\xa0Network,Another BERT that would learn the language at the paragraph scale,…Given that our task is a mere classification problem, the solution with a self-attention mechanism seemed to be pretty relevant for our case\\xa0because:It’s a bit smarter than a simple average-pooling, and it will automatically get rid of the useless paragraphs that contain no information for the legal domain. Indeed, the final paragraphs of French decisions are often related to the operative part of the judgment, and about who pays the costs. This is usually not relevant to our current\\xa0problem.It also provides some precious insights on how to best interpret the model. We can indeed have access to the attention weights and check on which paragraphs the model focused on the most for its prediction.With all that mind, here’s the final architecture for the classification task:Final architecture of our legal document classification on documents, using the legal camemBERTWe first tried to train the whole pipeline, including the fine-tuning of the legal camemBERT on this task, but we got memory errors. We quickly froze the BERT model and trained only the rest of the pipeline (attention layer + classification layer). It provided good results so we didn’t go with further experiments on an end-to-end training. This is something that we made a note of though, since unsupervised BERT outputs are known to be poor if not fine-tuned, as discussed earlier in this\\xa0article.ResultsThe goal here was not only to improve our legal domains classification, but also to show that we could achieve at least the same results as a simple TF-IDF\\xa0model.Dataset creationDeep learning in general often requires a consequent training set size. That’s why we used a semi-automatically labelled training dataset, labelled:by humans, using\\xa0Prodi.gywith business rules, using the associated court as a reference. If a decision is linked to another one from Labor court, it’s very likely that the decision is about Droit du travail(labor laws).with the most reliable predictions of our former algorithm, based on TF-IDF for the domain, and a legal taxonomy for the subdomain.Comparison between models and discussionWe achieved the same performance with our legal camemBERT and with a simple TF-IDF, which is actually good news! We indeed didn’t spend a lot of time on the modeling part of camemBERT, and this classification task is in the end a rather simple NLP\\xa0task.Moreover and perhaps just as interestingly, we noticed after a qualitative analysis of model’s prediction errors that the errors of the simple model were more often out of context. It means that when the TF-IDF gets it wrong, it’s really way off the mark. For example, this decision is predicted as Droit du transport with a probability of 0.96, instead of Droit des assurances because the decision is about a vehicle insurance claim and contains a lot of vocabulary related to transportation, and not that much about insurance.On the other hand, the legal camemBERT can of course be wrong, but it never steers too much out of context and will mostly predict subdomains that are very close, like Droit immobilier et de la construction and Droit de la copropriété et de la propriété immobilière, when we look at the confusion matrix.Moreover, CamemBERT managed to predict some subdomains that were not obvious at all, even for humans. For example, this decision has been predicted as Divorce et séparations de corpswithout any explicit mention of the word divorce in the decision! The subdomain here is very implicit and implied by a mention to a father that has to pay alimony to the mother of his\\xa0child.Let’s now have a look at the attention weights of our modeling. Here are some examples\\xa0below:Paragraph with the highest attention score (0.34) for the prediction of https://www.doctrine.fr/d/CA/Reims/2008/SK60FC7292250FC0B001E6 as Divorce et Séparation de\\xa0corpsParagraph with the highest attention score (0.26) for the prediction of https://www.doctrine.fr/d/CA/Rouen/2016/1F43DFAE32435B18DC90 as Droit des étrangers et de la nationalitéThese attention scores totally make sense, and confirmed the approach.We also confirmed that paragraphs related to generic procedures had a very low attention weight, like this\\xa0one:Paragraph with a very low attention weight of 0.01 for the prediction of https://www.doctrine.fr/d/CA/Rouen/2016/1F43DFAE32435B18DC90 as Droit des étrangers et de la nationalitéFinally, when we had a look at the errors of the models (both models), we quickly noticed that some classes were very well predicted and some others were not. Our intuition about the observed discrepancy boils down to the fact that language models are only ever as good as their training dataset. In our case, the issue seems to stem from volume and errors in the training set. This is definitely the next priority for this task to focus on, before trying to play with the different architectures. Indeed, the current one seems to work pretty well on subdomains when the training dataset is satisfactory.ConclusionWe built a legal language model with a state-of-the-art technique, that proved to be very efficient at capturing highly relevant information on a simple classification task. This is a huge step for Doctrine, as we have a lot of very complex tasks in Natural Language Processing to tackle! The granularity of this new language model, which can seamlessly provide token, paragraph and document embeddings will be key for us to find new applications for the technique on a wide array of complex Natural Language Processing tasks at Doctrine.In fact, the legal camemBERT has already found a second problem to tackle with the issue of semantic similarity between users and legal content in the context of a recommendation system and seems to already have yielded promising results, which we’ll be sharing in an upcoming blog post very soon. Stay\\xa0tuned!A single legal text representation at Doctrine: the legal camemBERT was originally published in Inside Doctrine on Medium, where people are continuing the conversation by highlighting and responding to this story.',\n",
       " 'The cleaned dataset and the pre-training models will facilitate the research of short-text conversation modeling. Code: https://github.com/thu-coai/CDial-GPT',\n",
       " 'Hello. I want to collect as many as papers as I can that will fall into this category. The main problem is that the \"tagging\" is not consistent for linguistic papers. Hence I\\'m looking for an exhausitve list of tags which are directly related to this field, in order to make better queries and find more relevant data.  Thanks!    submitted by    /u/quit_daedalus   [link] [comments]',\n",
       " 'Since the appearance of BERT, recent works including XLNet and RoBERTa utilize sentence embedding models pre-trained by large corpora and a large number of parameters. Code: https://github.com/snunlp/KR-BERT',\n",
       " 'Dialogue state modules are a useful component in a task-oriented dialogue system. Code: https://github.com/taolusi/dialogue-state-induction',\n",
       " 'We learn a feature center for each category and realize the global feature consistency by forcing the object features to approach class-specific centers. Code: https://github.com/xiaomengyc/I2C',\n",
       " 'Arbitrary-shaped text detection is a challenging task due to the complex geometric layouts of texts such as large aspect ratios, various scales, random rotations and curve shapes. Code: https://github.com/LianaWang/TextRay']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[doc.text for doc in raw_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>deep learning</th>\n",
       "      <th>natural language processing</th>\n",
       "      <th>computer vision</th>\n",
       "      <th>statistics</th>\n",
       "      <th>implementation</th>\n",
       "      <th>visualization</th>\n",
       "      <th>industry</th>\n",
       "      <th>software engineering</th>\n",
       "      <th>reddit question</th>\n",
       "      <th>arxiv</th>\n",
       "      <th>cloud computing</th>\n",
       "      <th>deployment</th>\n",
       "      <th>competitions</th>\n",
       "      <th>business</th>\n",
       "      <th>business intelligence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Evaluating the Impact of Knowledge Graph Context on Entity Disambiguation Models</td>\n",
       "      <td>Pretrained Transformer models have emerged as state-of-the-art approaches that learn contextual ...</td>\n",
       "      <td>0.613387</td>\n",
       "      <td>0.597722</td>\n",
       "      <td>0.531973</td>\n",
       "      <td>0.501481</td>\n",
       "      <td>0.593792</td>\n",
       "      <td>0.559076</td>\n",
       "      <td>0.545501</td>\n",
       "      <td>0.592912</td>\n",
       "      <td>0.543777</td>\n",
       "      <td>0.490492</td>\n",
       "      <td>0.511187</td>\n",
       "      <td>0.537554</td>\n",
       "      <td>0.530916</td>\n",
       "      <td>0.494104</td>\n",
       "      <td>0.496908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Feature Engineering with NLP</td>\n",
       "      <td>Converting tokens of text into features and applying machine learning and deep learning model on...</td>\n",
       "      <td>0.597072</td>\n",
       "      <td>0.590448</td>\n",
       "      <td>0.549067</td>\n",
       "      <td>0.511888</td>\n",
       "      <td>0.567869</td>\n",
       "      <td>0.536750</td>\n",
       "      <td>0.531344</td>\n",
       "      <td>0.617110</td>\n",
       "      <td>0.547273</td>\n",
       "      <td>0.493482</td>\n",
       "      <td>0.531765</td>\n",
       "      <td>0.509824</td>\n",
       "      <td>0.536120</td>\n",
       "      <td>0.519174</td>\n",
       "      <td>0.530965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Introduction to Natural Language Processing</td>\n",
       "      <td>NLP is a great tool to analyze text data and perform an amazing task when combined with machine ...</td>\n",
       "      <td>0.606703</td>\n",
       "      <td>0.586747</td>\n",
       "      <td>0.556306</td>\n",
       "      <td>0.513555</td>\n",
       "      <td>0.553962</td>\n",
       "      <td>0.538722</td>\n",
       "      <td>0.533227</td>\n",
       "      <td>0.608819</td>\n",
       "      <td>0.549520</td>\n",
       "      <td>0.514010</td>\n",
       "      <td>0.531522</td>\n",
       "      <td>0.506409</td>\n",
       "      <td>0.531768</td>\n",
       "      <td>0.515964</td>\n",
       "      <td>0.540105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A single legal text representation at Doctrine: the legal camemBERT</td>\n",
       "      <td>As a legal platform, Doctrine aggregates a lot of legal data with the intent of making them acce...</td>\n",
       "      <td>0.570231</td>\n",
       "      <td>0.586314</td>\n",
       "      <td>0.521751</td>\n",
       "      <td>0.499045</td>\n",
       "      <td>0.548911</td>\n",
       "      <td>0.511261</td>\n",
       "      <td>0.517473</td>\n",
       "      <td>0.595577</td>\n",
       "      <td>0.505991</td>\n",
       "      <td>0.492187</td>\n",
       "      <td>0.509414</td>\n",
       "      <td>0.505175</td>\n",
       "      <td>0.512034</td>\n",
       "      <td>0.511341</td>\n",
       "      <td>0.525712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Large-Scale Chinese Short-Text Conversation Dataset</td>\n",
       "      <td>The cleaned dataset and the pre-training models will facilitate the research of short-text conve...</td>\n",
       "      <td>0.621184</td>\n",
       "      <td>0.586691</td>\n",
       "      <td>0.545824</td>\n",
       "      <td>0.541583</td>\n",
       "      <td>0.584535</td>\n",
       "      <td>0.550647</td>\n",
       "      <td>0.527896</td>\n",
       "      <td>0.600209</td>\n",
       "      <td>0.548811</td>\n",
       "      <td>0.484411</td>\n",
       "      <td>0.517256</td>\n",
       "      <td>0.519267</td>\n",
       "      <td>0.528229</td>\n",
       "      <td>0.519199</td>\n",
       "      <td>0.530539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Q] Data scientist here, working on gathering a corpus of academic papers focusing on \"Cognitive...</td>\n",
       "      <td>Hello. I want to collect as many as papers as I can that will fall into this category. The main ...</td>\n",
       "      <td>0.555300</td>\n",
       "      <td>0.578011</td>\n",
       "      <td>0.498356</td>\n",
       "      <td>0.489413</td>\n",
       "      <td>0.526189</td>\n",
       "      <td>0.513210</td>\n",
       "      <td>0.489906</td>\n",
       "      <td>0.544217</td>\n",
       "      <td>0.557324</td>\n",
       "      <td>0.480271</td>\n",
       "      <td>0.496461</td>\n",
       "      <td>0.485666</td>\n",
       "      <td>0.530694</td>\n",
       "      <td>0.496379</td>\n",
       "      <td>0.504614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KR-BERT: A Small-Scale Korean-Specific Language Model</td>\n",
       "      <td>Since the appearance of BERT, recent works including XLNet and RoBERTa utilize sentence embeddin...</td>\n",
       "      <td>0.574174</td>\n",
       "      <td>0.594593</td>\n",
       "      <td>0.522638</td>\n",
       "      <td>0.532562</td>\n",
       "      <td>0.583562</td>\n",
       "      <td>0.552562</td>\n",
       "      <td>0.547111</td>\n",
       "      <td>0.580898</td>\n",
       "      <td>0.551625</td>\n",
       "      <td>0.498453</td>\n",
       "      <td>0.515522</td>\n",
       "      <td>0.564181</td>\n",
       "      <td>0.550184</td>\n",
       "      <td>0.508991</td>\n",
       "      <td>0.513304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dialogue State Induction Using Neural Latent Variable Models</td>\n",
       "      <td>Dialogue state modules are a useful component in a task-oriented dialogue system. Code: https://...</td>\n",
       "      <td>0.609547</td>\n",
       "      <td>0.595336</td>\n",
       "      <td>0.546996</td>\n",
       "      <td>0.492073</td>\n",
       "      <td>0.601822</td>\n",
       "      <td>0.568787</td>\n",
       "      <td>0.546473</td>\n",
       "      <td>0.602195</td>\n",
       "      <td>0.570310</td>\n",
       "      <td>0.499499</td>\n",
       "      <td>0.532563</td>\n",
       "      <td>0.543948</td>\n",
       "      <td>0.563158</td>\n",
       "      <td>0.529331</td>\n",
       "      <td>0.538693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Inter-Image Communication for Weakly Supervised Localization</td>\n",
       "      <td>We learn a feature center for each category and realize the global feature consistency by forcin...</td>\n",
       "      <td>0.593860</td>\n",
       "      <td>0.596002</td>\n",
       "      <td>0.541500</td>\n",
       "      <td>0.521783</td>\n",
       "      <td>0.593086</td>\n",
       "      <td>0.556799</td>\n",
       "      <td>0.535707</td>\n",
       "      <td>0.601382</td>\n",
       "      <td>0.539489</td>\n",
       "      <td>0.486664</td>\n",
       "      <td>0.553956</td>\n",
       "      <td>0.532525</td>\n",
       "      <td>0.545695</td>\n",
       "      <td>0.532982</td>\n",
       "      <td>0.542407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TextRay: Contour-based Geometric Modeling for Arbitrary-shaped Scene Text Detection</td>\n",
       "      <td>Arbitrary-shaped text detection is a challenging task due to the complex geometric layouts of te...</td>\n",
       "      <td>0.573135</td>\n",
       "      <td>0.569583</td>\n",
       "      <td>0.536931</td>\n",
       "      <td>0.505102</td>\n",
       "      <td>0.543021</td>\n",
       "      <td>0.542183</td>\n",
       "      <td>0.517943</td>\n",
       "      <td>0.571432</td>\n",
       "      <td>0.553461</td>\n",
       "      <td>0.498335</td>\n",
       "      <td>0.522298</td>\n",
       "      <td>0.509426</td>\n",
       "      <td>0.536340</td>\n",
       "      <td>0.498024</td>\n",
       "      <td>0.506026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 title  \\\n",
       "0                     Evaluating the Impact of Knowledge Graph Context on Entity Disambiguation Models   \n",
       "1                                                                         Feature Engineering with NLP   \n",
       "2                                                          Introduction to Natural Language Processing   \n",
       "3                                  A single legal text representation at Doctrine: the legal camemBERT   \n",
       "4                                                A Large-Scale Chinese Short-Text Conversation Dataset   \n",
       "5  [Q] Data scientist here, working on gathering a corpus of academic papers focusing on \"Cognitive...   \n",
       "6                                                KR-BERT: A Small-Scale Korean-Specific Language Model   \n",
       "7                                         Dialogue State Induction Using Neural Latent Variable Models   \n",
       "8                                         Inter-Image Communication for Weakly Supervised Localization   \n",
       "9                  TextRay: Contour-based Geometric Modeling for Arbitrary-shaped Scene Text Detection   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  Pretrained Transformer models have emerged as state-of-the-art approaches that learn contextual ...   \n",
       "1  Converting tokens of text into features and applying machine learning and deep learning model on...   \n",
       "2  NLP is a great tool to analyze text data and perform an amazing task when combined with machine ...   \n",
       "3  As a legal platform, Doctrine aggregates a lot of legal data with the intent of making them acce...   \n",
       "4  The cleaned dataset and the pre-training models will facilitate the research of short-text conve...   \n",
       "5  Hello. I want to collect as many as papers as I can that will fall into this category. The main ...   \n",
       "6  Since the appearance of BERT, recent works including XLNet and RoBERTa utilize sentence embeddin...   \n",
       "7  Dialogue state modules are a useful component in a task-oriented dialogue system. Code: https://...   \n",
       "8  We learn a feature center for each category and realize the global feature consistency by forcin...   \n",
       "9  Arbitrary-shaped text detection is a challenging task due to the complex geometric layouts of te...   \n",
       "\n",
       "   deep learning  natural language processing  computer vision  statistics  \\\n",
       "0       0.613387                     0.597722         0.531973    0.501481   \n",
       "1       0.597072                     0.590448         0.549067    0.511888   \n",
       "2       0.606703                     0.586747         0.556306    0.513555   \n",
       "3       0.570231                     0.586314         0.521751    0.499045   \n",
       "4       0.621184                     0.586691         0.545824    0.541583   \n",
       "5       0.555300                     0.578011         0.498356    0.489413   \n",
       "6       0.574174                     0.594593         0.522638    0.532562   \n",
       "7       0.609547                     0.595336         0.546996    0.492073   \n",
       "8       0.593860                     0.596002         0.541500    0.521783   \n",
       "9       0.573135                     0.569583         0.536931    0.505102   \n",
       "\n",
       "   implementation  visualization  industry  software engineering  \\\n",
       "0        0.593792       0.559076  0.545501              0.592912   \n",
       "1        0.567869       0.536750  0.531344              0.617110   \n",
       "2        0.553962       0.538722  0.533227              0.608819   \n",
       "3        0.548911       0.511261  0.517473              0.595577   \n",
       "4        0.584535       0.550647  0.527896              0.600209   \n",
       "5        0.526189       0.513210  0.489906              0.544217   \n",
       "6        0.583562       0.552562  0.547111              0.580898   \n",
       "7        0.601822       0.568787  0.546473              0.602195   \n",
       "8        0.593086       0.556799  0.535707              0.601382   \n",
       "9        0.543021       0.542183  0.517943              0.571432   \n",
       "\n",
       "   reddit question     arxiv  cloud computing  deployment  competitions  \\\n",
       "0         0.543777  0.490492         0.511187    0.537554      0.530916   \n",
       "1         0.547273  0.493482         0.531765    0.509824      0.536120   \n",
       "2         0.549520  0.514010         0.531522    0.506409      0.531768   \n",
       "3         0.505991  0.492187         0.509414    0.505175      0.512034   \n",
       "4         0.548811  0.484411         0.517256    0.519267      0.528229   \n",
       "5         0.557324  0.480271         0.496461    0.485666      0.530694   \n",
       "6         0.551625  0.498453         0.515522    0.564181      0.550184   \n",
       "7         0.570310  0.499499         0.532563    0.543948      0.563158   \n",
       "8         0.539489  0.486664         0.553956    0.532525      0.545695   \n",
       "9         0.553461  0.498335         0.522298    0.509426      0.536340   \n",
       "\n",
       "   business  business intelligence  \n",
       "0  0.494104               0.496908  \n",
       "1  0.519174               0.530965  \n",
       "2  0.515964               0.540105  \n",
       "3  0.511341               0.525712  \n",
       "4  0.519199               0.530539  \n",
       "5  0.496379               0.504614  \n",
       "6  0.508991               0.513304  \n",
       "7  0.529331               0.538693  \n",
       "8  0.532982               0.542407  \n",
       "9  0.498024               0.506026  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
