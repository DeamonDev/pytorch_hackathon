{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp haystack_code_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch\n",
    "\n",
    "from haystack import Finder\n",
    "from haystack.database.elasticsearch import ElasticsearchDocumentStore\n",
    "from haystack.database.memory import InMemoryDocumentStore\n",
    "\n",
    "from haystack.retriever.dense import EmbeddingRetriever\n",
    "from haystack.utils import print_answers\n",
    "from pytorch_hackathon import zero_shot_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kuba/Projects/pytorch_hackathon\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feeds.txt  topics.txt  zsl_feed_results.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rss_feed_urls = list(pd.read_table('data/feeds.txt', header=None).iloc[:,0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:08<00:00,  1.79it/s]\n",
      "/home/kuba/Projects/pytorch_hackathon/pytorch_hackathon/zero_shot_learning.py:69: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 69 of the file /home/kuba/Projects/pytorch_hackathon/pytorch_hackathon/zero_shot_learning.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  feed_df['text'] = feed_df['summary'].apply(lambda s: bs4.BeautifulSoup(s).text)\n"
     ]
    }
   ],
   "source": [
    "feed_df = zero_shot_learning.get_feed_df(rss_feed_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print = pprint.PrettyPrinter(indent=2).pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title_detail</th>\n",
       "      <th>links</th>\n",
       "      <th>link</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_detail</th>\n",
       "      <th>id</th>\n",
       "      <th>guidislink</th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "      <th>...</th>\n",
       "      <th>published_parsed</th>\n",
       "      <th>comments</th>\n",
       "      <th>authors</th>\n",
       "      <th>author</th>\n",
       "      <th>author_detail</th>\n",
       "      <th>updated</th>\n",
       "      <th>updated_parsed</th>\n",
       "      <th>content</th>\n",
       "      <th>href</th>\n",
       "      <th>media_thumbnail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I2L-MeshNet: Image-to-Lixel Prediction Network for Accurate 3D Human Pose an...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds....</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.c...</td>\n",
       "      <td>https://paperswithcode.com/paper/i2l-meshnet-image-to-lixel-prediction-network</td>\n",
       "      <td>Most of the previous image-based 3D human pose and mesh estimation methods e...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.c...</td>\n",
       "      <td>https://paperswithcode.com/paper/i2l-meshnet-image-to-lixel-prediction-network</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'term': '3d hand pose estimation', 'scheme': None, 'label': None}, {'term'...</td>\n",
       "      <td>Most of the previous image-based 3D human pose and mesh estimation methods e...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polysemy Deciphering Network for Robust Human-Object Interaction Detection</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds....</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.c...</td>\n",
       "      <td>https://paperswithcode.com/paper/polysemy-deciphering-network-for-robust-human</td>\n",
       "      <td>To address this issue, in this paper, we propose a novel Polysemy Decipherin...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.c...</td>\n",
       "      <td>https://paperswithcode.com/paper/polysemy-deciphering-network-for-robust-human</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'term': 'Human-object interaction detection', 'scheme': None, 'label': Non...</td>\n",
       "      <td>To address this issue, in this paper, we propose a novel Polysemy Decipherin...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cascade Graph Neural Networks for RGB-D Salient Object Detection</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds....</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.c...</td>\n",
       "      <td>https://paperswithcode.com/paper/cascade-graph-neural-networks-for-rgb-d</td>\n",
       "      <td>Current works either simply distill prior knowledge from the corresponding d...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.c...</td>\n",
       "      <td>https://paperswithcode.com/paper/cascade-graph-neural-networks-for-rgb-d</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'term': 'Salient object detection', 'scheme': None, 'label': None}]</td>\n",
       "      <td>Current works either simply distill prior knowledge from the corresponding d...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Convolutional Complex Knowledge Graph Embeddings</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds....</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.c...</td>\n",
       "      <td>https://paperswithcode.com/paper/convolutional-complex-knowledge-graph</td>\n",
       "      <td>In this paper, we study the problem of learning continuous vector representa...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.c...</td>\n",
       "      <td>https://paperswithcode.com/paper/convolutional-complex-knowledge-graph</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'term': 'Knowledge graph embeddings', 'scheme': None, 'label': None}, {'te...</td>\n",
       "      <td>In this paper, we study the problem of learning continuous vector representa...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quantum State Tomography with Conditional Generative Adversarial Networks</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds....</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.c...</td>\n",
       "      <td>https://paperswithcode.com/paper/quantum-state-tomography-with-conditional</td>\n",
       "      <td>We augment a CGAN with custom neural-network layers that enable conversion o...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.c...</td>\n",
       "      <td>https://paperswithcode.com/paper/quantum-state-tomography-with-conditional</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'term': 'Quantum state tomography', 'scheme': None, 'label': None}]</td>\n",
       "      <td>We augment a CGAN with custom neural-network layers that enable conversion o...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             title  \\\n",
       "0  I2L-MeshNet: Image-to-Lixel Prediction Network for Accurate 3D Human Pose an...   \n",
       "1       Polysemy Deciphering Network for Robust Human-Object Interaction Detection   \n",
       "2                 Cascade Graph Neural Networks for RGB-D Salient Object Detection   \n",
       "3                                 Convolutional Complex Knowledge Graph Embeddings   \n",
       "4        Quantum State Tomography with Conditional Generative Adversarial Networks   \n",
       "\n",
       "                                                                      title_detail  \\\n",
       "0  {'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds....   \n",
       "1  {'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds....   \n",
       "2  {'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds....   \n",
       "3  {'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds....   \n",
       "4  {'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds....   \n",
       "\n",
       "                                                                             links  \\\n",
       "0  [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.c...   \n",
       "1  [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.c...   \n",
       "2  [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.c...   \n",
       "3  [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.c...   \n",
       "4  [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.c...   \n",
       "\n",
       "                                                                             link  \\\n",
       "0  https://paperswithcode.com/paper/i2l-meshnet-image-to-lixel-prediction-network   \n",
       "1  https://paperswithcode.com/paper/polysemy-deciphering-network-for-robust-human   \n",
       "2        https://paperswithcode.com/paper/cascade-graph-neural-networks-for-rgb-d   \n",
       "3          https://paperswithcode.com/paper/convolutional-complex-knowledge-graph   \n",
       "4      https://paperswithcode.com/paper/quantum-state-tomography-with-conditional   \n",
       "\n",
       "                                                                           summary  \\\n",
       "0  Most of the previous image-based 3D human pose and mesh estimation methods e...   \n",
       "1  To address this issue, in this paper, we propose a novel Polysemy Decipherin...   \n",
       "2  Current works either simply distill prior knowledge from the corresponding d...   \n",
       "3  In this paper, we study the problem of learning continuous vector representa...   \n",
       "4  We augment a CGAN with custom neural-network layers that enable conversion o...   \n",
       "\n",
       "                                                                    summary_detail  \\\n",
       "0  {'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.c...   \n",
       "1  {'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.c...   \n",
       "2  {'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.c...   \n",
       "3  {'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.c...   \n",
       "4  {'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.c...   \n",
       "\n",
       "                                                                               id  \\\n",
       "0  https://paperswithcode.com/paper/i2l-meshnet-image-to-lixel-prediction-network   \n",
       "1  https://paperswithcode.com/paper/polysemy-deciphering-network-for-robust-human   \n",
       "2        https://paperswithcode.com/paper/cascade-graph-neural-networks-for-rgb-d   \n",
       "3          https://paperswithcode.com/paper/convolutional-complex-knowledge-graph   \n",
       "4      https://paperswithcode.com/paper/quantum-state-tomography-with-conditional   \n",
       "\n",
       "  guidislink  \\\n",
       "0      False   \n",
       "1      False   \n",
       "2      False   \n",
       "3      False   \n",
       "4      False   \n",
       "\n",
       "                                                                              tags  \\\n",
       "0  [{'term': '3d hand pose estimation', 'scheme': None, 'label': None}, {'term'...   \n",
       "1  [{'term': 'Human-object interaction detection', 'scheme': None, 'label': Non...   \n",
       "2            [{'term': 'Salient object detection', 'scheme': None, 'label': None}]   \n",
       "3  [{'term': 'Knowledge graph embeddings', 'scheme': None, 'label': None}, {'te...   \n",
       "4            [{'term': 'Quantum state tomography', 'scheme': None, 'label': None}]   \n",
       "\n",
       "                                                                              text  \\\n",
       "0  Most of the previous image-based 3D human pose and mesh estimation methods e...   \n",
       "1  To address this issue, in this paper, we propose a novel Polysemy Decipherin...   \n",
       "2  Current works either simply distill prior knowledge from the corresponding d...   \n",
       "3  In this paper, we study the problem of learning continuous vector representa...   \n",
       "4  We augment a CGAN with custom neural-network layers that enable conversion o...   \n",
       "\n",
       "   ... published_parsed comments authors author author_detail updated  \\\n",
       "0  ...              NaN      NaN     NaN    NaN           NaN     NaN   \n",
       "1  ...              NaN      NaN     NaN    NaN           NaN     NaN   \n",
       "2  ...              NaN      NaN     NaN    NaN           NaN     NaN   \n",
       "3  ...              NaN      NaN     NaN    NaN           NaN     NaN   \n",
       "4  ...              NaN      NaN     NaN    NaN           NaN     NaN   \n",
       "\n",
       "  updated_parsed content href media_thumbnail  \n",
       "0            NaN     NaN  NaN             NaN  \n",
       "1            NaN     NaN  NaN             NaN  \n",
       "2            NaN     NaN  NaN             NaN  \n",
       "3            NaN     NaN  NaN             NaN  \n",
       "4            NaN     NaN  NaN             NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "document_store = InMemoryDocumentStore(\n",
    "    embedding_field=\"article_emb\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/12/2020 17:13:10 - INFO - haystack.retriever.dense -   Init retriever using embeddings of model deepset/sentence_bert\n",
      "08/12/2020 17:13:10 - INFO - farm.utils -   device: cuda n_gpu: 1, distributed training: False, automatic mixed precision training: None\n",
      "08/12/2020 17:13:10 - INFO - farm.infer -   Could not find `deepset/sentence_bert` locally. Try to download from model hub ...\n",
      "08/12/2020 17:13:13 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n",
      "08/12/2020 17:13:18 - INFO - farm.utils -   device: cuda n_gpu: 1, distributed training: False, automatic mixed precision training: None\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "model_name = \"deepset/sentence_bert\"\n",
    "\n",
    "\n",
    "retriever = EmbeddingRetriever(\n",
    "    document_store=document_store,\n",
    "    embedding_model=model_name,\n",
    "    use_gpu=use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaptiveModel(\n",
       "  (language_model): Bert(\n",
       "    (model): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (prediction_heads): ModuleList()\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.embedding_model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'title_detail', 'links', 'link', 'summary', 'summary_detail',\n",
       "       'id', 'guidislink', 'tags', 'text', 'feed', 'published',\n",
       "       'published_parsed', 'comments', 'authors', 'author', 'author_detail',\n",
       "       'updated', 'updated_parsed', 'content', 'href', 'media_thumbnail'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "article_texts = feed_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples: 100%|██████████| 74/74 [00:10<00:00,  7.16 Batches/s]\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "\n",
    "article_embeddings = retriever.embed_queries(texts=list(article_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "feed_df['article_emb'] = article_embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "document_store.write_documents(feed_df.to_dict(orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To address this issue, in this paper, we propose a novel Polysemy Deciphering Network (PD-Net) that decodes the visual polysemy of verbs for HOI detection in three distinct ways. Code: https://github.com/MuchHair/PD-Net'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_df.iloc[1]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_to_dict(doc):\n",
    "    d = {}\n",
    "    d['text'] = doc.text\n",
    "    d['title'] = doc.meta['title']\n",
    "    d['score'] = doc.query_score\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_strings = [\n",
    "    'computer vision',\n",
    "    'deep learning',\n",
    "    'natural language processing'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = topic_strings[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 32.07 Batches/s]\n"
     ]
    }
   ],
   "source": [
    "results = [\n",
    "    doc_to_dict(doc)\n",
    "    for doc in retriever.retrieve(\n",
    "        topic\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ktrain\n",
    "\n",
    "zsl_clf = ktrain.text.ZeroShotClassifier(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [\n",
    "    zsl_clf.predict(d['text'], topic_strings=topic_strings, max_length=256, include_labels=True)\n",
    "    for d in results\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Syntactic annotation of corpora in the form of part-of-speech (POS) tags is a key requirement for both linguistic research and subsequent automated natural language processing (NLP) tasks. Code: https://github.com/stheid/SetPOS',\n",
       " 'title': 'Reliable Part-of-Speech Tagging of Historical Corpora through Set-Valued Prediction',\n",
       " 'score': 0.5372036650018498}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame.from_records(\n",
    "    {**result, **dict(doc_scores)}\n",
    "    for (result, doc_scores) in zip(results, scores)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>computer vision</th>\n",
       "      <th>deep learning</th>\n",
       "      <th>natural language processing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Syntactic annotation of corpora in the form of part-of-speech (POS) tags is ...</td>\n",
       "      <td>Reliable Part-of-Speech Tagging of Historical Corpora through Set-Valued Pre...</td>\n",
       "      <td>0.537204</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.004424</td>\n",
       "      <td>0.944371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In our approach, protected attributes are connected to evaluative words foun...</td>\n",
       "      <td>Discovering and Categorising Language Biases in Reddit</td>\n",
       "      <td>0.453108</td>\n",
       "      <td>0.003528</td>\n",
       "      <td>0.032202</td>\n",
       "      <td>0.454947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Artificial touch would seem well-suited for Reinforcement Learning (RL), sin...</td>\n",
       "      <td>Deep Reinforcement Learning for Tactile Robotics: Learning to Type on a Brai...</td>\n",
       "      <td>0.411201</td>\n",
       "      <td>0.004114</td>\n",
       "      <td>0.022183</td>\n",
       "      <td>0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We propose a novel algorithm, named Open-Edit, which is the first attempt on...</td>\n",
       "      <td>Open-Edit: Open-Domain Image Manipulation with Open-Vocabulary Instructions</td>\n",
       "      <td>0.401655</td>\n",
       "      <td>0.404642</td>\n",
       "      <td>0.097054</td>\n",
       "      <td>0.002871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A common task in computational text analyses is to quantify how two corpora ...</td>\n",
       "      <td>Generalized Word Shift Graphs: A Method for Visualizing and Explaining Pairw...</td>\n",
       "      <td>0.386268</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>0.076504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Neural Language Models and the Turing TestContinue reading on Towards AI — M...</td>\n",
       "      <td>Is GPT-3 ‘Human’?</td>\n",
       "      <td>0.380754</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.165146</td>\n",
       "      <td>0.663763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>To address this problem, we created a new dataset containing both synthetic ...</td>\n",
       "      <td>Synthetic to Real Unsupervised Domain Adaptation for Single-Stage Artwork Re...</td>\n",
       "      <td>0.364484</td>\n",
       "      <td>0.652031</td>\n",
       "      <td>0.566288</td>\n",
       "      <td>0.001007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>For addressing this issue, this paper leverages domain-specific mappings for...</td>\n",
       "      <td>Domain-Specific Mappings for Generative Adversarial Style Transfer</td>\n",
       "      <td>0.359442</td>\n",
       "      <td>0.008340</td>\n",
       "      <td>0.037381</td>\n",
       "      <td>0.002777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>To address this issue, in this paper, we propose a novel Polysemy Decipherin...</td>\n",
       "      <td>Polysemy Deciphering Network for Robust Human-Object Interaction Detection</td>\n",
       "      <td>0.346406</td>\n",
       "      <td>0.260132</td>\n",
       "      <td>0.065253</td>\n",
       "      <td>0.032847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hello! Would be grateful if you could share the criteria you use/have encoun...</td>\n",
       "      <td>Any translators or ML specialists here? How does one evaluate a translation ...</td>\n",
       "      <td>0.344971</td>\n",
       "      <td>0.190806</td>\n",
       "      <td>0.059315</td>\n",
       "      <td>0.518846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              text  \\\n",
       "0  Syntactic annotation of corpora in the form of part-of-speech (POS) tags is ...   \n",
       "1  In our approach, protected attributes are connected to evaluative words foun...   \n",
       "2  Artificial touch would seem well-suited for Reinforcement Learning (RL), sin...   \n",
       "3  We propose a novel algorithm, named Open-Edit, which is the first attempt on...   \n",
       "4  A common task in computational text analyses is to quantify how two corpora ...   \n",
       "5  Neural Language Models and the Turing TestContinue reading on Towards AI — M...   \n",
       "6  To address this problem, we created a new dataset containing both synthetic ...   \n",
       "7  For addressing this issue, this paper leverages domain-specific mappings for...   \n",
       "8  To address this issue, in this paper, we propose a novel Polysemy Decipherin...   \n",
       "9  Hello! Would be grateful if you could share the criteria you use/have encoun...   \n",
       "\n",
       "                                                                             title  \\\n",
       "0  Reliable Part-of-Speech Tagging of Historical Corpora through Set-Valued Pre...   \n",
       "1                           Discovering and Categorising Language Biases in Reddit   \n",
       "2  Deep Reinforcement Learning for Tactile Robotics: Learning to Type on a Brai...   \n",
       "3      Open-Edit: Open-Domain Image Manipulation with Open-Vocabulary Instructions   \n",
       "4  Generalized Word Shift Graphs: A Method for Visualizing and Explaining Pairw...   \n",
       "5                                                                Is GPT-3 ‘Human’?   \n",
       "6  Synthetic to Real Unsupervised Domain Adaptation for Single-Stage Artwork Re...   \n",
       "7               Domain-Specific Mappings for Generative Adversarial Style Transfer   \n",
       "8       Polysemy Deciphering Network for Robust Human-Object Interaction Detection   \n",
       "9  Any translators or ML specialists here? How does one evaluate a translation ...   \n",
       "\n",
       "      score  computer vision  deep learning  natural language processing  \n",
       "0  0.537204         0.001010       0.004424                     0.944371  \n",
       "1  0.453108         0.003528       0.032202                     0.454947  \n",
       "2  0.411201         0.004114       0.022183                     0.000430  \n",
       "3  0.401655         0.404642       0.097054                     0.002871  \n",
       "4  0.386268         0.000250       0.005168                     0.076504  \n",
       "5  0.380754         0.000435       0.165146                     0.663763  \n",
       "6  0.364484         0.652031       0.566288                     0.001007  \n",
       "7  0.359442         0.008340       0.037381                     0.002777  \n",
       "8  0.346406         0.260132       0.065253                     0.032847  \n",
       "9  0.344971         0.190806       0.059315                     0.518846  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
